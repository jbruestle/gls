/*
 * AUTOGENERATED tcarstens January 2014
 */
#ifndef __UL256_0__
#define __UL256_0__

#include "../stdint.hl"
#include "../rng.hl"


/*
 * ul256
 */
typedef struct ul256_s {
    uint32_t x[8];
} ul256[1];

inline void ul256_init(ul256 x) { return; }
inline void ul256_clear(ul256 x) { return; }

typedef struct mod256_s {
    ul256 n;
    uint32_t np;
    ul256 rsq;
} mod256[1];




/*
 * Setters
 */
inline void ul256_set_gp(__global struct ul256_s *dst, ul256 src) {
    dst->x[0] = src->x[0];
    dst->x[1] = src->x[1];
    dst->x[2] = src->x[2];
    dst->x[3] = src->x[3];
    dst->x[4] = src->x[4];
    dst->x[5] = src->x[5];
    dst->x[6] = src->x[6];
    dst->x[7] = src->x[7];
}
inline void ul256_set_pg(ul256 dst, __global struct ul256_s *src) {
    dst->x[0] = src->x[0];
    dst->x[1] = src->x[1];
    dst->x[2] = src->x[2];
    dst->x[3] = src->x[3];
    dst->x[4] = src->x[4];
    dst->x[5] = src->x[5];
    dst->x[6] = src->x[6];
    dst->x[7] = src->x[7];
}
inline void ul256_set_gg(__global struct ul256_s *dst, __global struct ul256_s *src) {
    dst->x[0] = src->x[0];
    dst->x[1] = src->x[1];
    dst->x[2] = src->x[2];
    dst->x[3] = src->x[3];
    dst->x[4] = src->x[4];
    dst->x[5] = src->x[5];
    dst->x[6] = src->x[6];
    dst->x[7] = src->x[7];
}
inline void ul256_set(ul256 dst, ul256 src) {
    dst->x[0] = src->x[0];
    dst->x[1] = src->x[1];
    dst->x[2] = src->x[2];
    dst->x[3] = src->x[3];
    dst->x[4] = src->x[4];
    dst->x[5] = src->x[5];
    dst->x[6] = src->x[6];
    dst->x[7] = src->x[7];
}
/*
 * Set a ul256 to a uint32_t
 */
inline void ul256_set_ui(ul256 dst, uint32_t i) {
    dst->x[0] = i;
    dst->x[1] = 0;
    dst->x[2] = 0;
    dst->x[3] = 0;
    dst->x[4] = 0;
    dst->x[5] = 0;
    dst->x[6] = 0;
    dst->x[7] = 0;
}

/*
 * Get a uint32_t out of a ul256
 */
inline uint32_t ul256_get_ui(ul256 src) {
    return src->x[0];
}




/*
 * Generate a random ul256
 */
inline void ul256_rand(struct rng_t *r, ul256 dst) {
    uint64_t w0 = rand_uint64(r);
    uint64_t w1 = rand_uint64(r);
    uint64_t w2 = rand_uint64(r);
    uint64_t w3 = rand_uint64(r);
    
    dst->x[0] = w0 & 0xffffffff;
    dst->x[1] = w0  >> 32;
    dst->x[2] = w1 & 0xffffffff;
    dst->x[3] = w1  >> 32;
    dst->x[4] = w2 & 0xffffffff;
    dst->x[5] = w2  >> 32;
    dst->x[6] = w3 & 0xffffffff;
    dst->x[7] = w3  >> 32;
}



/*
 * Compare two ul256's
 */
inline int ul256_cmp(ul256 src1, ul256 src2) {
    int r = 0;
    if (src1->x[7] > src2->x[7]) r = 1;
    else if (src1->x[7] < src2->x[7]) r = -1;
    else if (src1->x[6] > src2->x[6]) r = 1;
    else if (src1->x[6] < src2->x[6]) r = -1;
    else if (src1->x[5] > src2->x[5]) r = 1;
    else if (src1->x[5] < src2->x[5]) r = -1;
    else if (src1->x[4] > src2->x[4]) r = 1;
    else if (src1->x[4] < src2->x[4]) r = -1;
    else if (src1->x[3] > src2->x[3]) r = 1;
    else if (src1->x[3] < src2->x[3]) r = -1;
    else if (src1->x[2] > src2->x[2]) r = 1;
    else if (src1->x[2] < src2->x[2]) r = -1;
    else if (src1->x[1] > src2->x[1]) r = 1;
    else if (src1->x[1] < src2->x[1]) r = -1;
    else if (src1->x[0] > src2->x[0]) r = 1;
    else if (src1->x[0] < src2->x[0]) r = -1;
    return r;
}

/*
 * Compare a ul256 with a uint32_t
 */
inline int ul256_cmp_ui(ul256 src1, uint32_t src2) {
    int r = 0;
    if (src1->x[7] | src1->x[6] | src1->x[5] | src1->x[4] | src1->x[3] | src1->x[2] |  src1->x[1]) r = 1;
    else if (src1->x[0] > src2) r = 1;
    else if (src1->x[0] < src2) r = -1;
    return r;
}




/*
 * Add two ul256's
 */
inline void ul256_add(ul256 dst, ul256 src1, ul256 src2) {
    #if defined(UL_NVIDIA)
        asm(
          "add.cc.u32  %0, %8, %16;\n\t"
          "addc.cc.u32 %1, %9, %17;\n\t"
          "addc.cc.u32 %2, %10, %18;\n\t"
          "addc.cc.u32 %3, %11, %19;\n\t"
          "addc.cc.u32 %4, %12, %20;\n\t"
          "addc.cc.u32 %5, %13, %21;\n\t"
          "addc.cc.u32 %6, %14, %22;\n\t"
          "addc.u32    %7, %15, %23;\n\t"
          : "=r" (dst->x[0]), "=r" (dst->x[1]), "=r" (dst->x[2]), "=r" (dst->x[3]), "=r" (dst->x[4]), "=r" (dst->x[5]), "=r" (dst->x[6]), "=r" (dst->x[7])
          : "r" (src1->x[0]), "r" (src1->x[1]), "r" (src1->x[2]), "r" (src1->x[3]), "r" (src1->x[4]), "r" (src1->x[5]), "r" (src1->x[6]), "r" (src1->x[7]), 
            "r" (src2->x[0]), "r" (src2->x[1]), "r" (src2->x[2]), "r" (src2->x[3]), "r" (src2->x[4]), "r" (src2->x[5]), "r" (src2->x[6]), "r" (src2->x[7])
          : "cc"
        );
    #else
        ul256 d = {{{0}}};
        d->x[0] = (src1->x[0] & 0x7fffffff) + (src2->x[0] & 0x7fffffff) + 0;
        uint32_t c0 = (src1->x[0] >> 31) + (src2->x[0] >> 31) + (d->x[0] >> 31);
        d->x[0] = (c0 << 31) | (d->x[0] & 0x7fffffff);
        c0 = c0 >> 1;
        dst->x[0] = d->x[0];
        
        d->x[1] = (src1->x[1] & 0x7fffffff) + (src2->x[1] & 0x7fffffff) + c0;
        uint32_t c1 = (src1->x[1] >> 31) + (src2->x[1] >> 31) + (d->x[1] >> 31);
        d->x[1] = (c1 << 31) | (d->x[1] & 0x7fffffff);
        c1 = c1 >> 1;
        dst->x[1] = d->x[1];
        
        d->x[2] = (src1->x[2] & 0x7fffffff) + (src2->x[2] & 0x7fffffff) + c1;
        uint32_t c2 = (src1->x[2] >> 31) + (src2->x[2] >> 31) + (d->x[2] >> 31);
        d->x[2] = (c2 << 31) | (d->x[2] & 0x7fffffff);
        c2 = c2 >> 1;
        dst->x[2] = d->x[2];
        
        d->x[3] = (src1->x[3] & 0x7fffffff) + (src2->x[3] & 0x7fffffff) + c2;
        uint32_t c3 = (src1->x[3] >> 31) + (src2->x[3] >> 31) + (d->x[3] >> 31);
        d->x[3] = (c3 << 31) | (d->x[3] & 0x7fffffff);
        c3 = c3 >> 1;
        dst->x[3] = d->x[3];
        
        d->x[4] = (src1->x[4] & 0x7fffffff) + (src2->x[4] & 0x7fffffff) + c3;
        uint32_t c4 = (src1->x[4] >> 31) + (src2->x[4] >> 31) + (d->x[4] >> 31);
        d->x[4] = (c4 << 31) | (d->x[4] & 0x7fffffff);
        c4 = c4 >> 1;
        dst->x[4] = d->x[4];
        
        d->x[5] = (src1->x[5] & 0x7fffffff) + (src2->x[5] & 0x7fffffff) + c4;
        uint32_t c5 = (src1->x[5] >> 31) + (src2->x[5] >> 31) + (d->x[5] >> 31);
        d->x[5] = (c5 << 31) | (d->x[5] & 0x7fffffff);
        c5 = c5 >> 1;
        dst->x[5] = d->x[5];
        
        d->x[6] = (src1->x[6] & 0x7fffffff) + (src2->x[6] & 0x7fffffff) + c5;
        uint32_t c6 = (src1->x[6] >> 31) + (src2->x[6] >> 31) + (d->x[6] >> 31);
        d->x[6] = (c6 << 31) | (d->x[6] & 0x7fffffff);
        c6 = c6 >> 1;
        dst->x[6] = d->x[6];
        
        d->x[7] = (src1->x[7] & 0x7fffffff) + (src2->x[7] & 0x7fffffff) + c6;
        uint32_t c7 = (src1->x[7] >> 31) + (src2->x[7] >> 31) + (d->x[7] >> 31);
        d->x[7] = (c7 << 31) | (d->x[7] & 0x7fffffff);
        c7 = c7 >> 1;
        dst->x[7] = d->x[7];
        
    #endif
    return;
}
/*
 * Sub two ul256's
 */
inline void ul256_sub(ul256 dst, ul256 src1, ul256 src2) {
    #if defined(UL_NVIDIA)
        asm(
          "sub.cc.u32  %0, %8, %16;\n\t"
          "subc.cc.u32 %1, %9, %17;\n\t"
          "subc.cc.u32 %2, %10, %18;\n\t"
          "subc.cc.u32 %3, %11, %19;\n\t"
          "subc.cc.u32 %4, %12, %20;\n\t"
          "subc.cc.u32 %5, %13, %21;\n\t"
          "subc.cc.u32 %6, %14, %22;\n\t"
          "subc.u32    %7, %15, %23;\n\t"
          : "=r" (dst->x[0]), "=r" (dst->x[1]), "=r" (dst->x[2]), "=r" (dst->x[3]), "=r" (dst->x[4]), "=r" (dst->x[5]), "=r" (dst->x[6]), "=r" (dst->x[7])
          : "r" (src1->x[0]), "r" (src1->x[1]), "r" (src1->x[2]), "r" (src1->x[3]), "r" (src1->x[4]), "r" (src1->x[5]), "r" (src1->x[6]), "r" (src1->x[7]), 
            "r" (src2->x[0]), "r" (src2->x[1]), "r" (src2->x[2]), "r" (src2->x[3]), "r" (src2->x[4]), "r" (src2->x[5]), "r" (src2->x[6]), "r" (src2->x[7])
          : "cc"
        );
    #else
        ul256 d = {{{0}}};
        d->x[0] = (src1->x[0] & 0x7fffffff) - (src2->x[0] & 0x7fffffff) - 0;
        uint32_t b0 = (src1->x[0] >> 31) - (src2->x[0] >> 31) - (d->x[0] >> 31);
        d->x[0] = (b0 << 31) | (d->x[0] & 0x7fffffff);
        b0 = (b0 >> 1) & 1;
        dst->x[0] = d->x[0];
        
        d->x[1] = (src1->x[1] & 0x7fffffff) - (src2->x[1] & 0x7fffffff) - b0;
        uint32_t b1 = (src1->x[1] >> 31) - (src2->x[1] >> 31) - (d->x[1] >> 31);
        d->x[1] = (b1 << 31) | (d->x[1] & 0x7fffffff);
        b1 = (b1 >> 1) & 1;
        dst->x[1] = d->x[1];
        
        d->x[2] = (src1->x[2] & 0x7fffffff) - (src2->x[2] & 0x7fffffff) - b1;
        uint32_t b2 = (src1->x[2] >> 31) - (src2->x[2] >> 31) - (d->x[2] >> 31);
        d->x[2] = (b2 << 31) | (d->x[2] & 0x7fffffff);
        b2 = (b2 >> 1) & 1;
        dst->x[2] = d->x[2];
        
        d->x[3] = (src1->x[3] & 0x7fffffff) - (src2->x[3] & 0x7fffffff) - b2;
        uint32_t b3 = (src1->x[3] >> 31) - (src2->x[3] >> 31) - (d->x[3] >> 31);
        d->x[3] = (b3 << 31) | (d->x[3] & 0x7fffffff);
        b3 = (b3 >> 1) & 1;
        dst->x[3] = d->x[3];
        
        d->x[4] = (src1->x[4] & 0x7fffffff) - (src2->x[4] & 0x7fffffff) - b3;
        uint32_t b4 = (src1->x[4] >> 31) - (src2->x[4] >> 31) - (d->x[4] >> 31);
        d->x[4] = (b4 << 31) | (d->x[4] & 0x7fffffff);
        b4 = (b4 >> 1) & 1;
        dst->x[4] = d->x[4];
        
        d->x[5] = (src1->x[5] & 0x7fffffff) - (src2->x[5] & 0x7fffffff) - b4;
        uint32_t b5 = (src1->x[5] >> 31) - (src2->x[5] >> 31) - (d->x[5] >> 31);
        d->x[5] = (b5 << 31) | (d->x[5] & 0x7fffffff);
        b5 = (b5 >> 1) & 1;
        dst->x[5] = d->x[5];
        
        d->x[6] = (src1->x[6] & 0x7fffffff) - (src2->x[6] & 0x7fffffff) - b5;
        uint32_t b6 = (src1->x[6] >> 31) - (src2->x[6] >> 31) - (d->x[6] >> 31);
        d->x[6] = (b6 << 31) | (d->x[6] & 0x7fffffff);
        b6 = (b6 >> 1) & 1;
        dst->x[6] = d->x[6];
        
        d->x[7] = (src1->x[7] & 0x7fffffff) - (src2->x[7] & 0x7fffffff) - b6;
        uint32_t b7 = (src1->x[7] >> 31) - (src2->x[7] >> 31) - (d->x[7] >> 31);
        d->x[7] = (b7 << 31) | (d->x[7] & 0x7fffffff);
        b7 = (b7 >> 1) & 1;
        dst->x[7] = d->x[7];
        
    #endif
    return;
}
/*
 * Mul two ul256's
 */
inline void ul256_mul(ul256 dst, ul256 src1, ul256 src2) {
    #if defined(UL_NVIDIA)
        asm(
          "mul.lo.u32 %0, %8, %16;\n\t"
          "mul.hi.u32 %1, %8, %16;\n\t"
          "mad.lo.cc.u32 %1, %8, %17, %1;\n\t"
          "madc.hi.u32 %2, %8, %17, 0;\n\t"
          "mad.lo.cc.u32 %1, %9, %16, %1;\n\t"
          "madc.hi.cc.u32 %2, %9, %16, %2;\n\t"
          "madc.lo.u32 %3, %8, %19, 0;\n\t"
          "mad.lo.cc.u32 %2, %8, %18, %2;\n\t"
          "madc.hi.cc.u32 %3, %8, %18, %3;\n\t"
          "madc.lo.u32 %4, %8, %20, 0;\n\t"
          "mad.lo.cc.u32 %2, %9, %17, %2;\n\t"
          "madc.hi.cc.u32 %3, %9, %17, %3;\n\t"
          "madc.lo.cc.u32 %4, %9, %19, %4;\n\t"
          "madc.hi.u32 %5, %9, %19, 0;\n\t"
          "mad.lo.cc.u32 %2, %10, %16, %2;\n\t"
          "madc.hi.cc.u32 %3, %10, %16, %3;\n\t"
          "madc.lo.cc.u32 %4, %10, %18, %4;\n\t"
          "madc.hi.cc.u32 %5, %10, %18, %5;\n\t"
          "madc.lo.u32 %6, %8, %22, 0;\n\t"
          "mad.lo.cc.u32 %3, %9, %18, %3;\n\t"
          "madc.hi.cc.u32 %4, %9, %18, %4;\n\t"
          "madc.lo.cc.u32 %5, %8, %21, %5;\n\t"
          "madc.hi.cc.u32 %6, %8, %21, %6;\n\t"
          "madc.lo.u32 %7, %8, %23, 0;\n\t"
          "mad.lo.cc.u32 %3, %10, %17, %3;\n\t"
          "madc.hi.cc.u32 %4, %10, %17, %4;\n\t"
          "madc.lo.cc.u32 %5, %9, %20, %5;\n\t"
          "madc.hi.cc.u32 %6, %9, %20, %6;\n\t"
          "madc.lo.u32 %7, %9, %22, %7;\n\t"
          "mad.lo.cc.u32 %3, %11, %16, %3;\n\t"
          "madc.hi.cc.u32 %4, %11, %16, %4;\n\t"
          "madc.lo.cc.u32 %5, %10, %19, %5;\n\t"
          "madc.hi.cc.u32 %6, %10, %19, %6;\n\t"
          "madc.lo.u32 %7, %10, %21, %7;\n\t"
          "mad.lo.cc.u32 %4, %11, %17, %4;\n\t"
          "madc.hi.cc.u32 %5, %11, %17, %5;\n\t"
          "madc.lo.cc.u32 %6, %9, %21, %6;\n\t"
          "madc.hi.u32 %7, %9, %21, %7;\n\t"
          "mad.lo.cc.u32 %4, %12, %16, %4;\n\t"
          "madc.hi.cc.u32 %5, %12, %16, %5;\n\t"
          "madc.lo.cc.u32 %6, %10, %20, %6;\n\t"
          "madc.hi.u32 %7, %10, %20, %7;\n\t"
          "mad.hi.cc.u32 %4, %8, %19, %4;\n\t"
          "madc.lo.cc.u32 %5, %11, %18, %5;\n\t"
          "madc.hi.cc.u32 %6, %11, %18, %6;\n\t"
          "madc.lo.u32 %7, %11, %20, %7;\n\t"
          "mad.lo.cc.u32 %5, %12, %17, %5;\n\t"
          "madc.hi.cc.u32 %6, %12, %17, %6;\n\t"
          "madc.lo.u32 %7, %12, %19, %7;\n\t"
          "mad.lo.cc.u32 %5, %13, %16, %5;\n\t"
          "madc.hi.cc.u32 %6, %13, %16, %6;\n\t"
          "madc.lo.u32 %7, %13, %18, %7;\n\t"
          "mad.hi.cc.u32 %5, %8, %20, %5;\n\t"
          "madc.lo.cc.u32 %6, %11, %19, %6;\n\t"
          "madc.hi.u32 %7, %11, %19, %7;\n\t"
          "mad.lo.cc.u32 %6, %12, %18, %6;\n\t"
          "madc.hi.u32 %7, %12, %18, %7;\n\t"
          "mad.lo.cc.u32 %6, %13, %17, %6;\n\t"
          "madc.hi.u32 %7, %13, %17, %7;\n\t"
          "mad.lo.cc.u32 %6, %14, %16, %6;\n\t"
          "madc.hi.u32 %7, %14, %16, %7;\n\t"
          "mad.lo.u32 %7, %14, %17, %7;\n\t"
          "mad.lo.u32 %7, %15, %16, %7;\n\t"
          "mad.hi.u32 %7, %8, %22, %7;\n\t"
          : "=r" (dst->x[0]), "=r" (dst->x[1]), "=r" (dst->x[2]), "=r" (dst->x[3]), "=r" (dst->x[4]), "=r" (dst->x[5]), "=r" (dst->x[6]), "=r" (dst->x[7])
          : "r" (src1->x[0]), "r" (src1->x[1]), "r" (src1->x[2]), "r" (src1->x[3]), "r" (src1->x[4]), "r" (src1->x[5]), "r" (src1->x[6]), "r" (src1->x[7]), 
            "r" (src2->x[0]), "r" (src2->x[1]), "r" (src2->x[2]), "r" (src2->x[3]), "r" (src2->x[4]), "r" (src2->x[5]), "r" (src2->x[6]), "r" (src2->x[7])
          : "cc"
        );
    #else
        ul256 d = {{{0}}};
        
        uint64_t tmp0 = ((uint64_t)src1->x[0]) * ((uint64_t)src2->x[0]);
        ul256 tmp0_;
        tmp0_->x[0] = tmp0;
        tmp0_->x[1] = tmp0 >> 32;
        tmp0_->x[2] = 0;
        tmp0_->x[3] = 0;
        tmp0_->x[4] = 0;
        tmp0_->x[5] = 0;
        tmp0_->x[6] = 0;
        tmp0_->x[7] = 0;
        ul256_add(d, tmp0_, d);
        
        uint64_t tmp1 = ((uint64_t)src1->x[0]) * ((uint64_t)src2->x[1]);
        ul256 tmp1_;
        tmp1_->x[0] = 0;
        tmp1_->x[1] = tmp1;
        tmp1_->x[2] = tmp1 >> 32;
        tmp1_->x[3] = 0;
        tmp1_->x[4] = 0;
        tmp1_->x[5] = 0;
        tmp1_->x[6] = 0;
        tmp1_->x[7] = 0;
        ul256_add(d, tmp1_, d);
        
        uint64_t tmp2 = ((uint64_t)src1->x[1]) * ((uint64_t)src2->x[0]);
        ul256 tmp2_;
        tmp2_->x[0] = 0;
        tmp2_->x[1] = tmp2;
        tmp2_->x[2] = tmp2 >> 32;
        tmp2_->x[3] = 0;
        tmp2_->x[4] = 0;
        tmp2_->x[5] = 0;
        tmp2_->x[6] = 0;
        tmp2_->x[7] = 0;
        ul256_add(d, tmp2_, d);
        
        uint64_t tmp3 = ((uint64_t)src1->x[0]) * ((uint64_t)src2->x[2]);
        ul256 tmp3_;
        tmp3_->x[0] = 0;
        tmp3_->x[1] = 0;
        tmp3_->x[2] = tmp3;
        tmp3_->x[3] = tmp3 >> 32;
        tmp3_->x[4] = 0;
        tmp3_->x[5] = 0;
        tmp3_->x[6] = 0;
        tmp3_->x[7] = 0;
        ul256_add(d, tmp3_, d);
        
        uint64_t tmp4 = ((uint64_t)src1->x[1]) * ((uint64_t)src2->x[1]);
        ul256 tmp4_;
        tmp4_->x[0] = 0;
        tmp4_->x[1] = 0;
        tmp4_->x[2] = tmp4;
        tmp4_->x[3] = tmp4 >> 32;
        tmp4_->x[4] = 0;
        tmp4_->x[5] = 0;
        tmp4_->x[6] = 0;
        tmp4_->x[7] = 0;
        ul256_add(d, tmp4_, d);
        
        uint64_t tmp5 = ((uint64_t)src1->x[2]) * ((uint64_t)src2->x[0]);
        ul256 tmp5_;
        tmp5_->x[0] = 0;
        tmp5_->x[1] = 0;
        tmp5_->x[2] = tmp5;
        tmp5_->x[3] = tmp5 >> 32;
        tmp5_->x[4] = 0;
        tmp5_->x[5] = 0;
        tmp5_->x[6] = 0;
        tmp5_->x[7] = 0;
        ul256_add(d, tmp5_, d);
        
        uint64_t tmp6 = ((uint64_t)src1->x[0]) * ((uint64_t)src2->x[3]);
        ul256 tmp6_;
        tmp6_->x[0] = 0;
        tmp6_->x[1] = 0;
        tmp6_->x[2] = 0;
        tmp6_->x[3] = tmp6;
        tmp6_->x[4] = tmp6 >> 32;
        tmp6_->x[5] = 0;
        tmp6_->x[6] = 0;
        tmp6_->x[7] = 0;
        ul256_add(d, tmp6_, d);
        
        uint64_t tmp7 = ((uint64_t)src1->x[1]) * ((uint64_t)src2->x[2]);
        ul256 tmp7_;
        tmp7_->x[0] = 0;
        tmp7_->x[1] = 0;
        tmp7_->x[2] = 0;
        tmp7_->x[3] = tmp7;
        tmp7_->x[4] = tmp7 >> 32;
        tmp7_->x[5] = 0;
        tmp7_->x[6] = 0;
        tmp7_->x[7] = 0;
        ul256_add(d, tmp7_, d);
        
        uint64_t tmp8 = ((uint64_t)src1->x[2]) * ((uint64_t)src2->x[1]);
        ul256 tmp8_;
        tmp8_->x[0] = 0;
        tmp8_->x[1] = 0;
        tmp8_->x[2] = 0;
        tmp8_->x[3] = tmp8;
        tmp8_->x[4] = tmp8 >> 32;
        tmp8_->x[5] = 0;
        tmp8_->x[6] = 0;
        tmp8_->x[7] = 0;
        ul256_add(d, tmp8_, d);
        
        uint64_t tmp9 = ((uint64_t)src1->x[3]) * ((uint64_t)src2->x[0]);
        ul256 tmp9_;
        tmp9_->x[0] = 0;
        tmp9_->x[1] = 0;
        tmp9_->x[2] = 0;
        tmp9_->x[3] = tmp9;
        tmp9_->x[4] = tmp9 >> 32;
        tmp9_->x[5] = 0;
        tmp9_->x[6] = 0;
        tmp9_->x[7] = 0;
        ul256_add(d, tmp9_, d);
        
        uint64_t tmp10 = ((uint64_t)src1->x[0]) * ((uint64_t)src2->x[4]);
        ul256 tmp10_;
        tmp10_->x[0] = 0;
        tmp10_->x[1] = 0;
        tmp10_->x[2] = 0;
        tmp10_->x[3] = 0;
        tmp10_->x[4] = tmp10;
        tmp10_->x[5] = tmp10 >> 32;
        tmp10_->x[6] = 0;
        tmp10_->x[7] = 0;
        ul256_add(d, tmp10_, d);
        
        uint64_t tmp11 = ((uint64_t)src1->x[1]) * ((uint64_t)src2->x[3]);
        ul256 tmp11_;
        tmp11_->x[0] = 0;
        tmp11_->x[1] = 0;
        tmp11_->x[2] = 0;
        tmp11_->x[3] = 0;
        tmp11_->x[4] = tmp11;
        tmp11_->x[5] = tmp11 >> 32;
        tmp11_->x[6] = 0;
        tmp11_->x[7] = 0;
        ul256_add(d, tmp11_, d);
        
        uint64_t tmp12 = ((uint64_t)src1->x[2]) * ((uint64_t)src2->x[2]);
        ul256 tmp12_;
        tmp12_->x[0] = 0;
        tmp12_->x[1] = 0;
        tmp12_->x[2] = 0;
        tmp12_->x[3] = 0;
        tmp12_->x[4] = tmp12;
        tmp12_->x[5] = tmp12 >> 32;
        tmp12_->x[6] = 0;
        tmp12_->x[7] = 0;
        ul256_add(d, tmp12_, d);
        
        uint64_t tmp13 = ((uint64_t)src1->x[3]) * ((uint64_t)src2->x[1]);
        ul256 tmp13_;
        tmp13_->x[0] = 0;
        tmp13_->x[1] = 0;
        tmp13_->x[2] = 0;
        tmp13_->x[3] = 0;
        tmp13_->x[4] = tmp13;
        tmp13_->x[5] = tmp13 >> 32;
        tmp13_->x[6] = 0;
        tmp13_->x[7] = 0;
        ul256_add(d, tmp13_, d);
        
        uint64_t tmp14 = ((uint64_t)src1->x[4]) * ((uint64_t)src2->x[0]);
        ul256 tmp14_;
        tmp14_->x[0] = 0;
        tmp14_->x[1] = 0;
        tmp14_->x[2] = 0;
        tmp14_->x[3] = 0;
        tmp14_->x[4] = tmp14;
        tmp14_->x[5] = tmp14 >> 32;
        tmp14_->x[6] = 0;
        tmp14_->x[7] = 0;
        ul256_add(d, tmp14_, d);
        
        uint64_t tmp15 = ((uint64_t)src1->x[0]) * ((uint64_t)src2->x[5]);
        ul256 tmp15_;
        tmp15_->x[0] = 0;
        tmp15_->x[1] = 0;
        tmp15_->x[2] = 0;
        tmp15_->x[3] = 0;
        tmp15_->x[4] = 0;
        tmp15_->x[5] = tmp15;
        tmp15_->x[6] = tmp15 >> 32;
        tmp15_->x[7] = 0;
        ul256_add(d, tmp15_, d);
        
        uint64_t tmp16 = ((uint64_t)src1->x[1]) * ((uint64_t)src2->x[4]);
        ul256 tmp16_;
        tmp16_->x[0] = 0;
        tmp16_->x[1] = 0;
        tmp16_->x[2] = 0;
        tmp16_->x[3] = 0;
        tmp16_->x[4] = 0;
        tmp16_->x[5] = tmp16;
        tmp16_->x[6] = tmp16 >> 32;
        tmp16_->x[7] = 0;
        ul256_add(d, tmp16_, d);
        
        uint64_t tmp17 = ((uint64_t)src1->x[2]) * ((uint64_t)src2->x[3]);
        ul256 tmp17_;
        tmp17_->x[0] = 0;
        tmp17_->x[1] = 0;
        tmp17_->x[2] = 0;
        tmp17_->x[3] = 0;
        tmp17_->x[4] = 0;
        tmp17_->x[5] = tmp17;
        tmp17_->x[6] = tmp17 >> 32;
        tmp17_->x[7] = 0;
        ul256_add(d, tmp17_, d);
        
        uint64_t tmp18 = ((uint64_t)src1->x[3]) * ((uint64_t)src2->x[2]);
        ul256 tmp18_;
        tmp18_->x[0] = 0;
        tmp18_->x[1] = 0;
        tmp18_->x[2] = 0;
        tmp18_->x[3] = 0;
        tmp18_->x[4] = 0;
        tmp18_->x[5] = tmp18;
        tmp18_->x[6] = tmp18 >> 32;
        tmp18_->x[7] = 0;
        ul256_add(d, tmp18_, d);
        
        uint64_t tmp19 = ((uint64_t)src1->x[4]) * ((uint64_t)src2->x[1]);
        ul256 tmp19_;
        tmp19_->x[0] = 0;
        tmp19_->x[1] = 0;
        tmp19_->x[2] = 0;
        tmp19_->x[3] = 0;
        tmp19_->x[4] = 0;
        tmp19_->x[5] = tmp19;
        tmp19_->x[6] = tmp19 >> 32;
        tmp19_->x[7] = 0;
        ul256_add(d, tmp19_, d);
        
        uint64_t tmp20 = ((uint64_t)src1->x[5]) * ((uint64_t)src2->x[0]);
        ul256 tmp20_;
        tmp20_->x[0] = 0;
        tmp20_->x[1] = 0;
        tmp20_->x[2] = 0;
        tmp20_->x[3] = 0;
        tmp20_->x[4] = 0;
        tmp20_->x[5] = tmp20;
        tmp20_->x[6] = tmp20 >> 32;
        tmp20_->x[7] = 0;
        ul256_add(d, tmp20_, d);
        
        uint64_t tmp21 = ((uint64_t)src1->x[0]) * ((uint64_t)src2->x[6]);
        ul256 tmp21_;
        tmp21_->x[0] = 0;
        tmp21_->x[1] = 0;
        tmp21_->x[2] = 0;
        tmp21_->x[3] = 0;
        tmp21_->x[4] = 0;
        tmp21_->x[5] = 0;
        tmp21_->x[6] = tmp21;
        tmp21_->x[7] = tmp21 >> 32;
        ul256_add(d, tmp21_, d);
        
        uint64_t tmp22 = ((uint64_t)src1->x[1]) * ((uint64_t)src2->x[5]);
        ul256 tmp22_;
        tmp22_->x[0] = 0;
        tmp22_->x[1] = 0;
        tmp22_->x[2] = 0;
        tmp22_->x[3] = 0;
        tmp22_->x[4] = 0;
        tmp22_->x[5] = 0;
        tmp22_->x[6] = tmp22;
        tmp22_->x[7] = tmp22 >> 32;
        ul256_add(d, tmp22_, d);
        
        uint64_t tmp23 = ((uint64_t)src1->x[2]) * ((uint64_t)src2->x[4]);
        ul256 tmp23_;
        tmp23_->x[0] = 0;
        tmp23_->x[1] = 0;
        tmp23_->x[2] = 0;
        tmp23_->x[3] = 0;
        tmp23_->x[4] = 0;
        tmp23_->x[5] = 0;
        tmp23_->x[6] = tmp23;
        tmp23_->x[7] = tmp23 >> 32;
        ul256_add(d, tmp23_, d);
        
        uint64_t tmp24 = ((uint64_t)src1->x[3]) * ((uint64_t)src2->x[3]);
        ul256 tmp24_;
        tmp24_->x[0] = 0;
        tmp24_->x[1] = 0;
        tmp24_->x[2] = 0;
        tmp24_->x[3] = 0;
        tmp24_->x[4] = 0;
        tmp24_->x[5] = 0;
        tmp24_->x[6] = tmp24;
        tmp24_->x[7] = tmp24 >> 32;
        ul256_add(d, tmp24_, d);
        
        uint64_t tmp25 = ((uint64_t)src1->x[4]) * ((uint64_t)src2->x[2]);
        ul256 tmp25_;
        tmp25_->x[0] = 0;
        tmp25_->x[1] = 0;
        tmp25_->x[2] = 0;
        tmp25_->x[3] = 0;
        tmp25_->x[4] = 0;
        tmp25_->x[5] = 0;
        tmp25_->x[6] = tmp25;
        tmp25_->x[7] = tmp25 >> 32;
        ul256_add(d, tmp25_, d);
        
        uint64_t tmp26 = ((uint64_t)src1->x[5]) * ((uint64_t)src2->x[1]);
        ul256 tmp26_;
        tmp26_->x[0] = 0;
        tmp26_->x[1] = 0;
        tmp26_->x[2] = 0;
        tmp26_->x[3] = 0;
        tmp26_->x[4] = 0;
        tmp26_->x[5] = 0;
        tmp26_->x[6] = tmp26;
        tmp26_->x[7] = tmp26 >> 32;
        ul256_add(d, tmp26_, d);
        
        uint64_t tmp27 = ((uint64_t)src1->x[6]) * ((uint64_t)src2->x[0]);
        ul256 tmp27_;
        tmp27_->x[0] = 0;
        tmp27_->x[1] = 0;
        tmp27_->x[2] = 0;
        tmp27_->x[3] = 0;
        tmp27_->x[4] = 0;
        tmp27_->x[5] = 0;
        tmp27_->x[6] = tmp27;
        tmp27_->x[7] = tmp27 >> 32;
        ul256_add(d, tmp27_, d);
        
        uint64_t tmp28 = ((uint64_t)src1->x[0]) * ((uint64_t)src2->x[7]);
        ul256 tmp28_;
        tmp28_->x[0] = 0;
        tmp28_->x[1] = 0;
        tmp28_->x[2] = 0;
        tmp28_->x[3] = 0;
        tmp28_->x[4] = 0;
        tmp28_->x[5] = 0;
        tmp28_->x[6] = 0;
        tmp28_->x[7] = tmp28;
        ul256_add(d, tmp28_, d);
        
        uint64_t tmp29 = ((uint64_t)src1->x[1]) * ((uint64_t)src2->x[6]);
        ul256 tmp29_;
        tmp29_->x[0] = 0;
        tmp29_->x[1] = 0;
        tmp29_->x[2] = 0;
        tmp29_->x[3] = 0;
        tmp29_->x[4] = 0;
        tmp29_->x[5] = 0;
        tmp29_->x[6] = 0;
        tmp29_->x[7] = tmp29;
        ul256_add(d, tmp29_, d);
        
        uint64_t tmp30 = ((uint64_t)src1->x[2]) * ((uint64_t)src2->x[5]);
        ul256 tmp30_;
        tmp30_->x[0] = 0;
        tmp30_->x[1] = 0;
        tmp30_->x[2] = 0;
        tmp30_->x[3] = 0;
        tmp30_->x[4] = 0;
        tmp30_->x[5] = 0;
        tmp30_->x[6] = 0;
        tmp30_->x[7] = tmp30;
        ul256_add(d, tmp30_, d);
        
        uint64_t tmp31 = ((uint64_t)src1->x[3]) * ((uint64_t)src2->x[4]);
        ul256 tmp31_;
        tmp31_->x[0] = 0;
        tmp31_->x[1] = 0;
        tmp31_->x[2] = 0;
        tmp31_->x[3] = 0;
        tmp31_->x[4] = 0;
        tmp31_->x[5] = 0;
        tmp31_->x[6] = 0;
        tmp31_->x[7] = tmp31;
        ul256_add(d, tmp31_, d);
        
        uint64_t tmp32 = ((uint64_t)src1->x[4]) * ((uint64_t)src2->x[3]);
        ul256 tmp32_;
        tmp32_->x[0] = 0;
        tmp32_->x[1] = 0;
        tmp32_->x[2] = 0;
        tmp32_->x[3] = 0;
        tmp32_->x[4] = 0;
        tmp32_->x[5] = 0;
        tmp32_->x[6] = 0;
        tmp32_->x[7] = tmp32;
        ul256_add(d, tmp32_, d);
        
        uint64_t tmp33 = ((uint64_t)src1->x[5]) * ((uint64_t)src2->x[2]);
        ul256 tmp33_;
        tmp33_->x[0] = 0;
        tmp33_->x[1] = 0;
        tmp33_->x[2] = 0;
        tmp33_->x[3] = 0;
        tmp33_->x[4] = 0;
        tmp33_->x[5] = 0;
        tmp33_->x[6] = 0;
        tmp33_->x[7] = tmp33;
        ul256_add(d, tmp33_, d);
        
        uint64_t tmp34 = ((uint64_t)src1->x[6]) * ((uint64_t)src2->x[1]);
        ul256 tmp34_;
        tmp34_->x[0] = 0;
        tmp34_->x[1] = 0;
        tmp34_->x[2] = 0;
        tmp34_->x[3] = 0;
        tmp34_->x[4] = 0;
        tmp34_->x[5] = 0;
        tmp34_->x[6] = 0;
        tmp34_->x[7] = tmp34;
        ul256_add(d, tmp34_, d);
        
        uint64_t tmp35 = ((uint64_t)src1->x[7]) * ((uint64_t)src2->x[0]);
        ul256 tmp35_;
        tmp35_->x[0] = 0;
        tmp35_->x[1] = 0;
        tmp35_->x[2] = 0;
        tmp35_->x[3] = 0;
        tmp35_->x[4] = 0;
        tmp35_->x[5] = 0;
        tmp35_->x[6] = 0;
        tmp35_->x[7] = tmp35;
        ul256_add(d, tmp35_, d);
        
        dst->x[0] = d->x[0];
        dst->x[1] = d->x[1];
        dst->x[2] = d->x[2];
        dst->x[3] = d->x[3];
        dst->x[4] = d->x[4];
        dst->x[5] = d->x[5];
        dst->x[6] = d->x[6];
        dst->x[7] = d->x[7];
    #endif
    return;
}




/*
 * Initialize mod256
 */
inline void mod256_init(mod256 n) {
}

/*
 * Add two ul256's modulo another
 */
inline void ul256_modadd(ul256 dst, ul256 src1, ul256 src2, mod256 n) {
    ul256_add(dst, src1, src2);
    if (ul256_cmp(dst, n->n) >= 0)
        ul256_sub(dst, dst, n->n);
}

/*
 * Subtract one ul256 from another modulo a third
 */
inline void ul256_modsub(ul256 dst, ul256 src1, ul256 src2, mod256 n) {
    ul256 tr1, tr2;
    ul256_sub(tr1, src1, src2);
    ul256_add(tr2, tr1, n->n);
    if (ul256_cmp(src1, src2) >= 0)
        ul256_set(dst, tr1);
    else
        ul256_set(dst, tr2);
}

/*
 * Mul two ul256's modulo a third, followed by Montgomery reduction
 */
void ul256_modmul(ul256 _dst, ul256 _src1, ul256 _src2, mod256 n);
void ul256_modmul(ul256 _dst, ul256 _src1, ul256 _src2, mod256 n) {
    #if defined(UL_NVIDIA)
        volatile ul256 src1;
        volatile ul256 src2;
        /* ul256_set(src1, _src1); */
        src1->x[0] = _src1->x[0];
        src1->x[1] = _src1->x[1];
        src1->x[2] = _src1->x[2];
        src1->x[3] = _src1->x[3];
        src1->x[4] = _src1->x[4];
        src1->x[5] = _src1->x[5];
        src1->x[6] = _src1->x[6];
        src1->x[7] = _src1->x[7];
        /* ul256_set(src2, _src2); */
        src2->x[0] = _src2->x[0];
        src2->x[1] = _src2->x[1];
        src2->x[2] = _src2->x[2];
        src2->x[3] = _src2->x[3];
        src2->x[4] = _src2->x[4];
        src2->x[5] = _src2->x[5];
        src2->x[6] = _src2->x[6];
        src2->x[7] = _src2->x[7];
        
        uint32_t q = 0;
        ul256 dst = {{{0}}};
        uint32_t dst_8 = 0;
        
        asm(
          /* Compute c_0..7 for the product a*b, with carry-out to dst_8 */
          "mad.lo.cc.u32  %0, %10, %18, %0;\n\t"  /* c_0 += lo(a_0, b_0) */
          "madc.hi.cc.u32 %1, %10, %18, %1;\n\t"  /* c_1 += hi(a_0, b_0) */
          "madc.lo.cc.u32 %2, %10, %20, %2;\n\t"  /* c_2 += lo(a_0, b_2) */
          "madc.hi.cc.u32 %3, %10, %20, %3;\n\t"  /* c_3 += hi(a_0, b_2) */
          "madc.lo.cc.u32 %4, %10, %22, %4;\n\t"  /* c_4 += lo(a_0, b_4) */
          "madc.hi.cc.u32 %5, %10, %22, %5;\n\t"  /* c_5 += hi(a_0, b_4) */
          "madc.lo.cc.u32 %6, %10, %24, %6;\n\t"  /* c_6 += lo(a_0, b_6) */
          "madc.hi.cc.u32 %7, %10, %24, %7;\n\t"  /* c_7 += hi(a_0, b_6) */
          "addc.u32 %8, %8, 0;\n\t"  /* accum carry in c_8 */
          "mad.lo.cc.u32  %1, %10, %19, %1;\n\t"  /* c_1 += lo(a_0, b_1) */
          "madc.hi.cc.u32 %2, %10, %19, %2;\n\t"  /* c_2 += hi(a_0, b_1) */
          "madc.lo.cc.u32 %3, %10, %21, %3;\n\t"  /* c_3 += lo(a_0, b_3) */
          "madc.hi.cc.u32 %4, %10, %21, %4;\n\t"  /* c_4 += hi(a_0, b_3) */
          "madc.lo.cc.u32 %5, %10, %23, %5;\n\t"  /* c_5 += lo(a_0, b_5) */
          "madc.hi.cc.u32 %6, %10, %23, %6;\n\t"  /* c_6 += hi(a_0, b_5) */
          "madc.lo.cc.u32 %7, %10, %25, %7;\n\t"  /* c_7 += lo(a_0, b_7) */
          "addc.u32 %8, %8, 0;\n\t"  /* accum carry in c_8 */
          "mad.lo.cc.u32  %1, %11, %18, %1;\n\t"  /* c_1 += lo(a_1, b_0) */
          "madc.hi.cc.u32 %2, %11, %18, %2;\n\t"  /* c_2 += hi(a_1, b_0) */
          "madc.lo.cc.u32 %3, %11, %20, %3;\n\t"  /* c_3 += lo(a_1, b_2) */
          "madc.hi.cc.u32 %4, %11, %20, %4;\n\t"  /* c_4 += hi(a_1, b_2) */
          "madc.lo.cc.u32 %5, %11, %22, %5;\n\t"  /* c_5 += lo(a_1, b_4) */
          "madc.hi.cc.u32 %6, %11, %22, %6;\n\t"  /* c_6 += hi(a_1, b_4) */
          "madc.lo.cc.u32 %7, %11, %24, %7;\n\t"  /* c_7 += lo(a_1, b_6) */
          "addc.u32 %8, %8, 0;\n\t"  /* accum carry in c_8 */
          "mad.lo.cc.u32  %2, %11, %19, %2;\n\t"  /* c_2 += lo(a_1, b_1) */
          "madc.hi.cc.u32 %3, %11, %19, %3;\n\t"  /* c_3 += hi(a_1, b_1) */
          "madc.lo.cc.u32 %4, %11, %21, %4;\n\t"  /* c_4 += lo(a_1, b_3) */
          "madc.hi.cc.u32 %5, %11, %21, %5;\n\t"  /* c_5 += hi(a_1, b_3) */
          "madc.lo.cc.u32 %6, %11, %23, %6;\n\t"  /* c_6 += lo(a_1, b_5) */
          "madc.hi.cc.u32 %7, %11, %23, %7;\n\t"  /* c_7 += hi(a_1, b_5) */
          "addc.u32 %8, %8, 0;\n\t"  /* accum carry in c_8 */
          "mad.lo.cc.u32  %2, %12, %18, %2;\n\t"  /* c_2 += lo(a_2, b_0) */
          "madc.hi.cc.u32 %3, %12, %18, %3;\n\t"  /* c_3 += hi(a_2, b_0) */
          "madc.lo.cc.u32 %4, %12, %20, %4;\n\t"  /* c_4 += lo(a_2, b_2) */
          "madc.hi.cc.u32 %5, %12, %20, %5;\n\t"  /* c_5 += hi(a_2, b_2) */
          "madc.lo.cc.u32 %6, %12, %22, %6;\n\t"  /* c_6 += lo(a_2, b_4) */
          "madc.hi.cc.u32 %7, %12, %22, %7;\n\t"  /* c_7 += hi(a_2, b_4) */
          "addc.u32 %8, %8, 0;\n\t"  /* accum carry in c_8 */
          "mad.lo.cc.u32  %3, %12, %19, %3;\n\t"  /* c_3 += lo(a_2, b_1) */
          "madc.hi.cc.u32 %4, %12, %19, %4;\n\t"  /* c_4 += hi(a_2, b_1) */
          "madc.lo.cc.u32 %5, %12, %21, %5;\n\t"  /* c_5 += lo(a_2, b_3) */
          "madc.hi.cc.u32 %6, %12, %21, %6;\n\t"  /* c_6 += hi(a_2, b_3) */
          "madc.lo.cc.u32 %7, %12, %23, %7;\n\t"  /* c_7 += lo(a_2, b_5) */
          "addc.u32 %8, %8, 0;\n\t"  /* accum carry in c_8 */
          "mad.lo.cc.u32  %3, %13, %18, %3;\n\t"  /* c_3 += lo(a_3, b_0) */
          "madc.hi.cc.u32 %4, %13, %18, %4;\n\t"  /* c_4 += hi(a_3, b_0) */
          "madc.lo.cc.u32 %5, %13, %20, %5;\n\t"  /* c_5 += lo(a_3, b_2) */
          "madc.hi.cc.u32 %6, %13, %20, %6;\n\t"  /* c_6 += hi(a_3, b_2) */
          "madc.lo.cc.u32 %7, %13, %22, %7;\n\t"  /* c_7 += lo(a_3, b_4) */
          "addc.u32 %8, %8, 0;\n\t"  /* accum carry in c_8 */
          "mad.lo.cc.u32  %4, %13, %19, %4;\n\t"  /* c_4 += lo(a_3, b_1) */
          "madc.hi.cc.u32 %5, %13, %19, %5;\n\t"  /* c_5 += hi(a_3, b_1) */
          "madc.lo.cc.u32 %6, %13, %21, %6;\n\t"  /* c_6 += lo(a_3, b_3) */
          "madc.hi.cc.u32 %7, %13, %21, %7;\n\t"  /* c_7 += hi(a_3, b_3) */
          "addc.u32 %8, %8, 0;\n\t"  /* accum carry in c_8 */
          "mad.lo.cc.u32  %4, %14, %18, %4;\n\t"  /* c_4 += lo(a_4, b_0) */
          "madc.hi.cc.u32 %5, %14, %18, %5;\n\t"  /* c_5 += hi(a_4, b_0) */
          "madc.lo.cc.u32 %6, %14, %20, %6;\n\t"  /* c_6 += lo(a_4, b_2) */
          "madc.hi.cc.u32 %7, %14, %20, %7;\n\t"  /* c_7 += hi(a_4, b_2) */
          "addc.u32 %8, %8, 0;\n\t"  /* accum carry in c_8 */
          "mad.lo.cc.u32  %5, %14, %19, %5;\n\t"  /* c_5 += lo(a_4, b_1) */
          "madc.hi.cc.u32 %6, %14, %19, %6;\n\t"  /* c_6 += hi(a_4, b_1) */
          "madc.lo.cc.u32 %7, %14, %21, %7;\n\t"  /* c_7 += lo(a_4, b_3) */
          "addc.u32 %8, %8, 0;\n\t"  /* accum carry in c_8 */
          "mad.lo.cc.u32  %5, %15, %18, %5;\n\t"  /* c_5 += lo(a_5, b_0) */
          "madc.hi.cc.u32 %6, %15, %18, %6;\n\t"  /* c_6 += hi(a_5, b_0) */
          "madc.lo.cc.u32 %7, %15, %20, %7;\n\t"  /* c_7 += lo(a_5, b_2) */
          "addc.u32 %8, %8, 0;\n\t"  /* accum carry in c_8 */
          "mad.lo.cc.u32  %6, %15, %19, %6;\n\t"  /* c_6 += lo(a_5, b_1) */
          "madc.hi.cc.u32 %7, %15, %19, %7;\n\t"  /* c_7 += hi(a_5, b_1) */
          "addc.u32 %8, %8, 0;\n\t"  /* accum carry in c_8 */
          "mad.lo.cc.u32  %6, %16, %18, %6;\n\t"  /* c_6 += lo(a_6, b_0) */
          "madc.hi.cc.u32 %7, %16, %18, %7;\n\t"  /* c_7 += hi(a_6, b_0) */
          "addc.u32 %8, %8, 0;\n\t"  /* accum carry in c_8 */
          "mad.lo.cc.u32  %7, %16, %19, %7;\n\t"  /* c_7 += lo(a_6, b_1) */
          "addc.u32 %8, %8, 0;\n\t"  /* accum carry in c_8 */
          "mad.lo.cc.u32  %7, %17, %18, %7;\n\t"  /* c_7 += lo(a_7, b_0) */
          "addc.u32 %8, %8, 0;\n\t"  /* accum carry in c_8 */
          
          /* Add in the qN's */
          /* n = 0... */
            /* Compute q = mu * c_0 */
            "mov.u32 %9, %0;\n\t"
            "mul.lo.u32 %9, %9, %34;\n\t"
            /* Update c_0 with qN_0 */
            "mad.lo.cc.u32 %0, %9, %26, %0;\n\t"  /* c_0 += lo(q, n_0) */
            /* Shift */
            "mov.u32 %0, %1;\n\t"  /* dst_0 <- c_1 */
            "mov.u32 %1, %2;\n\t"  /* dst_1 <- c_2 */
            "mov.u32 %2, %3;\n\t"  /* dst_2 <- c_3 */
            "mov.u32 %3, %4;\n\t"  /* dst_3 <- c_4 */
            "mov.u32 %4, %5;\n\t"  /* dst_4 <- c_5 */
            "mov.u32 %5, %6;\n\t"  /* dst_5 <- c_6 */
            "mov.u32 %6, %7;\n\t"  /* dst_6 <- c_7 */
            "mov.u32 %7, %8;\n\t"  /* dst_7 <- c_8 */
            "xor.b32 %8, %8, %8;\n\t"  /* dst_8 <- c_9 */
            /* Compute and add-in qN, with carry-out to dst_8 */
            "madc.hi.cc.u32 %0, %9, %26, %0;\n\t"  /* c_1 += hi(q, n_0) */
            "madc.lo.cc.u32 %1, %9, %28, %1;\n\t"  /* c_2 += lo(q, n_2) */
            "madc.hi.cc.u32 %2, %9, %28, %2;\n\t"  /* c_3 += hi(q, n_2) */
            "madc.lo.cc.u32 %3, %9, %30, %3;\n\t"  /* c_4 += lo(q, n_4) */
            "madc.hi.cc.u32 %4, %9, %30, %4;\n\t"  /* c_5 += hi(q, n_4) */
            "madc.lo.cc.u32 %5, %9, %32, %5;\n\t"  /* c_6 += lo(q, n_6) */
            "madc.hi.cc.u32 %6, %9, %32, %6;\n\t"  /* c_7 += hi(q, n_6) */
            "addc.cc.u32 %7, %7, 0;\n\t"  /* accum carry in dst_7 */
            "addc.u32    %8, %8, 0;\n\t"  /* accum carry in dst_8 */
            "mad.lo.cc.u32  %0, %9, %27, %0;\n\t"  /* c_1 += lo(q, n_1) */
            "madc.hi.cc.u32 %1, %9, %27, %1;\n\t"  /* c_2 += hi(q, n_1) */
            "madc.lo.cc.u32 %2, %9, %29, %2;\n\t"  /* c_3 += lo(q, n_3) */
            "madc.hi.cc.u32 %3, %9, %29, %3;\n\t"  /* c_4 += hi(q, n_3) */
            "madc.lo.cc.u32 %4, %9, %31, %4;\n\t"  /* c_5 += lo(q, n_5) */
            "madc.hi.cc.u32 %5, %9, %31, %5;\n\t"  /* c_6 += hi(q, n_5) */
            "madc.lo.cc.u32 %6, %9, %33, %6;\n\t"  /* c_7 += lo(q, n_7) */
            "madc.hi.cc.u32 %7, %9, %33, %7;\n\t"  /* c_8 += hi(q, n_7) */
            "addc.u32    %8, %8, 0;\n\t"  /* accum carry in dst_8 */
          /* n = 1... */
            /* Compute q = mu * c_1 */
            "mov.u32 %9, %0;\n\t"
            "mul.lo.u32 %9, %9, %34;\n\t"
            /* Update c_1 with qN_0 */
            "mad.lo.cc.u32 %0, %9, %26, %0;\n\t"  /* c_1 += lo(q, n_0) */
            /* Shift */
            "mov.u32 %0, %1;\n\t"  /* dst_0 <- c_2 */
            "mov.u32 %1, %2;\n\t"  /* dst_1 <- c_3 */
            "mov.u32 %2, %3;\n\t"  /* dst_2 <- c_4 */
            "mov.u32 %3, %4;\n\t"  /* dst_3 <- c_5 */
            "mov.u32 %4, %5;\n\t"  /* dst_4 <- c_6 */
            "mov.u32 %5, %6;\n\t"  /* dst_5 <- c_7 */
            "mov.u32 %6, %7;\n\t"  /* dst_6 <- c_8 */
            "mov.u32 %7, %8;\n\t"  /* dst_7 <- c_9 */
            "xor.b32 %8, %8, %8;\n\t"  /* dst_8 <- c_10 */
            /* Compute and add-in qN, with carry-out to dst_8 */
            "madc.hi.cc.u32 %0, %9, %26, %0;\n\t"  /* c_2 += hi(q, n_0) */
            "madc.lo.cc.u32 %1, %9, %28, %1;\n\t"  /* c_3 += lo(q, n_2) */
            "madc.hi.cc.u32 %2, %9, %28, %2;\n\t"  /* c_4 += hi(q, n_2) */
            "madc.lo.cc.u32 %3, %9, %30, %3;\n\t"  /* c_5 += lo(q, n_4) */
            "madc.hi.cc.u32 %4, %9, %30, %4;\n\t"  /* c_6 += hi(q, n_4) */
            "madc.lo.cc.u32 %5, %9, %32, %5;\n\t"  /* c_7 += lo(q, n_6) */
            "madc.hi.cc.u32 %6, %9, %32, %6;\n\t"  /* c_8 += hi(q, n_6) */
            "addc.cc.u32 %7, %7, 0;\n\t"  /* accum carry in dst_7 */
            "addc.u32    %8, %8, 0;\n\t"  /* accum carry in dst_8 */
            "mad.lo.cc.u32  %0, %9, %27, %0;\n\t"  /* c_1 += lo(q, n_1) */
            "madc.hi.cc.u32 %1, %9, %27, %1;\n\t"  /* c_2 += hi(q, n_1) */
            "madc.lo.cc.u32 %2, %9, %29, %2;\n\t"  /* c_3 += lo(q, n_3) */
            "madc.hi.cc.u32 %3, %9, %29, %3;\n\t"  /* c_4 += hi(q, n_3) */
            "madc.lo.cc.u32 %4, %9, %31, %4;\n\t"  /* c_5 += lo(q, n_5) */
            "madc.hi.cc.u32 %5, %9, %31, %5;\n\t"  /* c_6 += hi(q, n_5) */
            "madc.lo.cc.u32 %6, %9, %33, %6;\n\t"  /* c_7 += lo(q, n_7) */
            "madc.hi.cc.u32 %7, %9, %33, %7;\n\t"  /* c_8 += hi(q, n_7) */
            "addc.u32    %8, %8, 0;\n\t"  /* accum carry in dst_8 */
          /* n = 2... */
            /* Compute q = mu * c_2 */
            "mov.u32 %9, %0;\n\t"
            "mul.lo.u32 %9, %9, %34;\n\t"
            /* Update c_2 with qN_0 */
            "mad.lo.cc.u32 %0, %9, %26, %0;\n\t"  /* c_2 += lo(q, n_0) */
            /* Shift */
            "mov.u32 %0, %1;\n\t"  /* dst_0 <- c_3 */
            "mov.u32 %1, %2;\n\t"  /* dst_1 <- c_4 */
            "mov.u32 %2, %3;\n\t"  /* dst_2 <- c_5 */
            "mov.u32 %3, %4;\n\t"  /* dst_3 <- c_6 */
            "mov.u32 %4, %5;\n\t"  /* dst_4 <- c_7 */
            "mov.u32 %5, %6;\n\t"  /* dst_5 <- c_8 */
            "mov.u32 %6, %7;\n\t"  /* dst_6 <- c_9 */
            "mov.u32 %7, %8;\n\t"  /* dst_7 <- c_10 */
            "xor.b32 %8, %8, %8;\n\t"  /* dst_8 <- c_11 */
            /* Compute and add-in qN, with carry-out to dst_8 */
            "madc.hi.cc.u32 %0, %9, %26, %0;\n\t"  /* c_3 += hi(q, n_0) */
            "madc.lo.cc.u32 %1, %9, %28, %1;\n\t"  /* c_4 += lo(q, n_2) */
            "madc.hi.cc.u32 %2, %9, %28, %2;\n\t"  /* c_5 += hi(q, n_2) */
            "madc.lo.cc.u32 %3, %9, %30, %3;\n\t"  /* c_6 += lo(q, n_4) */
            "madc.hi.cc.u32 %4, %9, %30, %4;\n\t"  /* c_7 += hi(q, n_4) */
            "madc.lo.cc.u32 %5, %9, %32, %5;\n\t"  /* c_8 += lo(q, n_6) */
            "madc.hi.cc.u32 %6, %9, %32, %6;\n\t"  /* c_9 += hi(q, n_6) */
            "addc.cc.u32 %7, %7, 0;\n\t"  /* accum carry in dst_7 */
            "addc.u32    %8, %8, 0;\n\t"  /* accum carry in dst_8 */
            "mad.lo.cc.u32  %0, %9, %27, %0;\n\t"  /* c_1 += lo(q, n_1) */
            "madc.hi.cc.u32 %1, %9, %27, %1;\n\t"  /* c_2 += hi(q, n_1) */
            "madc.lo.cc.u32 %2, %9, %29, %2;\n\t"  /* c_3 += lo(q, n_3) */
            "madc.hi.cc.u32 %3, %9, %29, %3;\n\t"  /* c_4 += hi(q, n_3) */
            "madc.lo.cc.u32 %4, %9, %31, %4;\n\t"  /* c_5 += lo(q, n_5) */
            "madc.hi.cc.u32 %5, %9, %31, %5;\n\t"  /* c_6 += hi(q, n_5) */
            "madc.lo.cc.u32 %6, %9, %33, %6;\n\t"  /* c_7 += lo(q, n_7) */
            "madc.hi.cc.u32 %7, %9, %33, %7;\n\t"  /* c_8 += hi(q, n_7) */
            "addc.u32    %8, %8, 0;\n\t"  /* accum carry in dst_8 */
          /* n = 3... */
            /* Compute q = mu * c_3 */
            "mov.u32 %9, %0;\n\t"
            "mul.lo.u32 %9, %9, %34;\n\t"
            /* Update c_3 with qN_0 */
            "mad.lo.cc.u32 %0, %9, %26, %0;\n\t"  /* c_3 += lo(q, n_0) */
            /* Shift */
            "mov.u32 %0, %1;\n\t"  /* dst_0 <- c_4 */
            "mov.u32 %1, %2;\n\t"  /* dst_1 <- c_5 */
            "mov.u32 %2, %3;\n\t"  /* dst_2 <- c_6 */
            "mov.u32 %3, %4;\n\t"  /* dst_3 <- c_7 */
            "mov.u32 %4, %5;\n\t"  /* dst_4 <- c_8 */
            "mov.u32 %5, %6;\n\t"  /* dst_5 <- c_9 */
            "mov.u32 %6, %7;\n\t"  /* dst_6 <- c_10 */
            "mov.u32 %7, %8;\n\t"  /* dst_7 <- c_11 */
            "xor.b32 %8, %8, %8;\n\t"  /* dst_8 <- c_12 */
            /* Compute and add-in qN, with carry-out to dst_8 */
            "madc.hi.cc.u32 %0, %9, %26, %0;\n\t"  /* c_4 += hi(q, n_0) */
            "madc.lo.cc.u32 %1, %9, %28, %1;\n\t"  /* c_5 += lo(q, n_2) */
            "madc.hi.cc.u32 %2, %9, %28, %2;\n\t"  /* c_6 += hi(q, n_2) */
            "madc.lo.cc.u32 %3, %9, %30, %3;\n\t"  /* c_7 += lo(q, n_4) */
            "madc.hi.cc.u32 %4, %9, %30, %4;\n\t"  /* c_8 += hi(q, n_4) */
            "madc.lo.cc.u32 %5, %9, %32, %5;\n\t"  /* c_9 += lo(q, n_6) */
            "madc.hi.cc.u32 %6, %9, %32, %6;\n\t"  /* c_10 += hi(q, n_6) */
            "addc.cc.u32 %7, %7, 0;\n\t"  /* accum carry in dst_7 */
            "addc.u32    %8, %8, 0;\n\t"  /* accum carry in dst_8 */
            "mad.lo.cc.u32  %0, %9, %27, %0;\n\t"  /* c_1 += lo(q, n_1) */
            "madc.hi.cc.u32 %1, %9, %27, %1;\n\t"  /* c_2 += hi(q, n_1) */
            "madc.lo.cc.u32 %2, %9, %29, %2;\n\t"  /* c_3 += lo(q, n_3) */
            "madc.hi.cc.u32 %3, %9, %29, %3;\n\t"  /* c_4 += hi(q, n_3) */
            "madc.lo.cc.u32 %4, %9, %31, %4;\n\t"  /* c_5 += lo(q, n_5) */
            "madc.hi.cc.u32 %5, %9, %31, %5;\n\t"  /* c_6 += hi(q, n_5) */
            "madc.lo.cc.u32 %6, %9, %33, %6;\n\t"  /* c_7 += lo(q, n_7) */
            "madc.hi.cc.u32 %7, %9, %33, %7;\n\t"  /* c_8 += hi(q, n_7) */
            "addc.u32    %8, %8, 0;\n\t"  /* accum carry in dst_8 */
          /* n = 4... */
            /* Compute q = mu * c_4 */
            "mov.u32 %9, %0;\n\t"
            "mul.lo.u32 %9, %9, %34;\n\t"
            /* Update c_4 with qN_0 */
            "mad.lo.cc.u32 %0, %9, %26, %0;\n\t"  /* c_4 += lo(q, n_0) */
            /* Shift */
            "mov.u32 %0, %1;\n\t"  /* dst_0 <- c_5 */
            "mov.u32 %1, %2;\n\t"  /* dst_1 <- c_6 */
            "mov.u32 %2, %3;\n\t"  /* dst_2 <- c_7 */
            "mov.u32 %3, %4;\n\t"  /* dst_3 <- c_8 */
            "mov.u32 %4, %5;\n\t"  /* dst_4 <- c_9 */
            "mov.u32 %5, %6;\n\t"  /* dst_5 <- c_10 */
            "mov.u32 %6, %7;\n\t"  /* dst_6 <- c_11 */
            "mov.u32 %7, %8;\n\t"  /* dst_7 <- c_12 */
            "xor.b32 %8, %8, %8;\n\t"  /* dst_8 <- c_13 */
            /* Compute and add-in qN, with carry-out to dst_8 */
            "madc.hi.cc.u32 %0, %9, %26, %0;\n\t"  /* c_5 += hi(q, n_0) */
            "madc.lo.cc.u32 %1, %9, %28, %1;\n\t"  /* c_6 += lo(q, n_2) */
            "madc.hi.cc.u32 %2, %9, %28, %2;\n\t"  /* c_7 += hi(q, n_2) */
            "madc.lo.cc.u32 %3, %9, %30, %3;\n\t"  /* c_8 += lo(q, n_4) */
            "madc.hi.cc.u32 %4, %9, %30, %4;\n\t"  /* c_9 += hi(q, n_4) */
            "madc.lo.cc.u32 %5, %9, %32, %5;\n\t"  /* c_10 += lo(q, n_6) */
            "madc.hi.cc.u32 %6, %9, %32, %6;\n\t"  /* c_11 += hi(q, n_6) */
            "addc.cc.u32 %7, %7, 0;\n\t"  /* accum carry in dst_7 */
            "addc.u32    %8, %8, 0;\n\t"  /* accum carry in dst_8 */
            "mad.lo.cc.u32  %0, %9, %27, %0;\n\t"  /* c_1 += lo(q, n_1) */
            "madc.hi.cc.u32 %1, %9, %27, %1;\n\t"  /* c_2 += hi(q, n_1) */
            "madc.lo.cc.u32 %2, %9, %29, %2;\n\t"  /* c_3 += lo(q, n_3) */
            "madc.hi.cc.u32 %3, %9, %29, %3;\n\t"  /* c_4 += hi(q, n_3) */
            "madc.lo.cc.u32 %4, %9, %31, %4;\n\t"  /* c_5 += lo(q, n_5) */
            "madc.hi.cc.u32 %5, %9, %31, %5;\n\t"  /* c_6 += hi(q, n_5) */
            "madc.lo.cc.u32 %6, %9, %33, %6;\n\t"  /* c_7 += lo(q, n_7) */
            "madc.hi.cc.u32 %7, %9, %33, %7;\n\t"  /* c_8 += hi(q, n_7) */
            "addc.u32    %8, %8, 0;\n\t"  /* accum carry in dst_8 */
          /* n = 5... */
            /* Compute q = mu * c_5 */
            "mov.u32 %9, %0;\n\t"
            "mul.lo.u32 %9, %9, %34;\n\t"
            /* Update c_5 with qN_0 */
            "mad.lo.cc.u32 %0, %9, %26, %0;\n\t"  /* c_5 += lo(q, n_0) */
            /* Shift */
            "mov.u32 %0, %1;\n\t"  /* dst_0 <- c_6 */
            "mov.u32 %1, %2;\n\t"  /* dst_1 <- c_7 */
            "mov.u32 %2, %3;\n\t"  /* dst_2 <- c_8 */
            "mov.u32 %3, %4;\n\t"  /* dst_3 <- c_9 */
            "mov.u32 %4, %5;\n\t"  /* dst_4 <- c_10 */
            "mov.u32 %5, %6;\n\t"  /* dst_5 <- c_11 */
            "mov.u32 %6, %7;\n\t"  /* dst_6 <- c_12 */
            "mov.u32 %7, %8;\n\t"  /* dst_7 <- c_13 */
            "xor.b32 %8, %8, %8;\n\t"  /* dst_8 <- c_14 */
            /* Compute and add-in qN, with carry-out to dst_8 */
            "madc.hi.cc.u32 %0, %9, %26, %0;\n\t"  /* c_6 += hi(q, n_0) */
            "madc.lo.cc.u32 %1, %9, %28, %1;\n\t"  /* c_7 += lo(q, n_2) */
            "madc.hi.cc.u32 %2, %9, %28, %2;\n\t"  /* c_8 += hi(q, n_2) */
            "madc.lo.cc.u32 %3, %9, %30, %3;\n\t"  /* c_9 += lo(q, n_4) */
            "madc.hi.cc.u32 %4, %9, %30, %4;\n\t"  /* c_10 += hi(q, n_4) */
            "madc.lo.cc.u32 %5, %9, %32, %5;\n\t"  /* c_11 += lo(q, n_6) */
            "madc.hi.cc.u32 %6, %9, %32, %6;\n\t"  /* c_12 += hi(q, n_6) */
            "addc.cc.u32 %7, %7, 0;\n\t"  /* accum carry in dst_7 */
            "addc.u32    %8, %8, 0;\n\t"  /* accum carry in dst_8 */
            "mad.lo.cc.u32  %0, %9, %27, %0;\n\t"  /* c_1 += lo(q, n_1) */
            "madc.hi.cc.u32 %1, %9, %27, %1;\n\t"  /* c_2 += hi(q, n_1) */
            "madc.lo.cc.u32 %2, %9, %29, %2;\n\t"  /* c_3 += lo(q, n_3) */
            "madc.hi.cc.u32 %3, %9, %29, %3;\n\t"  /* c_4 += hi(q, n_3) */
            "madc.lo.cc.u32 %4, %9, %31, %4;\n\t"  /* c_5 += lo(q, n_5) */
            "madc.hi.cc.u32 %5, %9, %31, %5;\n\t"  /* c_6 += hi(q, n_5) */
            "madc.lo.cc.u32 %6, %9, %33, %6;\n\t"  /* c_7 += lo(q, n_7) */
            "madc.hi.cc.u32 %7, %9, %33, %7;\n\t"  /* c_8 += hi(q, n_7) */
            "addc.u32    %8, %8, 0;\n\t"  /* accum carry in dst_8 */
          /* n = 6... */
            /* Compute q = mu * c_6 */
            "mov.u32 %9, %0;\n\t"
            "mul.lo.u32 %9, %9, %34;\n\t"
            /* Update c_6 with qN_0 */
            "mad.lo.cc.u32 %0, %9, %26, %0;\n\t"  /* c_6 += lo(q, n_0) */
            /* Shift */
            "mov.u32 %0, %1;\n\t"  /* dst_0 <- c_7 */
            "mov.u32 %1, %2;\n\t"  /* dst_1 <- c_8 */
            "mov.u32 %2, %3;\n\t"  /* dst_2 <- c_9 */
            "mov.u32 %3, %4;\n\t"  /* dst_3 <- c_10 */
            "mov.u32 %4, %5;\n\t"  /* dst_4 <- c_11 */
            "mov.u32 %5, %6;\n\t"  /* dst_5 <- c_12 */
            "mov.u32 %6, %7;\n\t"  /* dst_6 <- c_13 */
            "mov.u32 %7, %8;\n\t"  /* dst_7 <- c_14 */
            "xor.b32 %8, %8, %8;\n\t"  /* dst_8 <- c_15 */
            /* Compute and add-in qN, with carry-out to dst_8 */
            "madc.hi.cc.u32 %0, %9, %26, %0;\n\t"  /* c_7 += hi(q, n_0) */
            "madc.lo.cc.u32 %1, %9, %28, %1;\n\t"  /* c_8 += lo(q, n_2) */
            "madc.hi.cc.u32 %2, %9, %28, %2;\n\t"  /* c_9 += hi(q, n_2) */
            "madc.lo.cc.u32 %3, %9, %30, %3;\n\t"  /* c_10 += lo(q, n_4) */
            "madc.hi.cc.u32 %4, %9, %30, %4;\n\t"  /* c_11 += hi(q, n_4) */
            "madc.lo.cc.u32 %5, %9, %32, %5;\n\t"  /* c_12 += lo(q, n_6) */
            "madc.hi.cc.u32 %6, %9, %32, %6;\n\t"  /* c_13 += hi(q, n_6) */
            "addc.cc.u32 %7, %7, 0;\n\t"  /* accum carry in dst_7 */
            "addc.u32    %8, %8, 0;\n\t"  /* accum carry in dst_8 */
            "mad.lo.cc.u32  %0, %9, %27, %0;\n\t"  /* c_1 += lo(q, n_1) */
            "madc.hi.cc.u32 %1, %9, %27, %1;\n\t"  /* c_2 += hi(q, n_1) */
            "madc.lo.cc.u32 %2, %9, %29, %2;\n\t"  /* c_3 += lo(q, n_3) */
            "madc.hi.cc.u32 %3, %9, %29, %3;\n\t"  /* c_4 += hi(q, n_3) */
            "madc.lo.cc.u32 %4, %9, %31, %4;\n\t"  /* c_5 += lo(q, n_5) */
            "madc.hi.cc.u32 %5, %9, %31, %5;\n\t"  /* c_6 += hi(q, n_5) */
            "madc.lo.cc.u32 %6, %9, %33, %6;\n\t"  /* c_7 += lo(q, n_7) */
            "madc.hi.cc.u32 %7, %9, %33, %7;\n\t"  /* c_8 += hi(q, n_7) */
            "addc.u32    %8, %8, 0;\n\t"  /* accum carry in dst_8 */
          /* n = 7... */
            /* Compute q = mu * c_7 */
            "mov.u32 %9, %0;\n\t"
            "mul.lo.u32 %9, %9, %34;\n\t"
            /* Update c_7 with qN_0 */
            "mad.lo.cc.u32 %0, %9, %26, %0;\n\t"  /* c_7 += lo(q, n_0) */
            /* Shift */
            "mov.u32 %0, %1;\n\t"  /* dst_0 <- c_8 */
            "mov.u32 %1, %2;\n\t"  /* dst_1 <- c_9 */
            "mov.u32 %2, %3;\n\t"  /* dst_2 <- c_10 */
            "mov.u32 %3, %4;\n\t"  /* dst_3 <- c_11 */
            "mov.u32 %4, %5;\n\t"  /* dst_4 <- c_12 */
            "mov.u32 %5, %6;\n\t"  /* dst_5 <- c_13 */
            "mov.u32 %6, %7;\n\t"  /* dst_6 <- c_14 */
            "mov.u32 %7, %8;\n\t"  /* dst_7 <- c_15 */
            "xor.b32 %8, %8, %8;\n\t"  /* dst_8 <- c_16 */
            /* Compute and add-in qN, with carry-out to dst_8 */
            "madc.hi.cc.u32 %0, %9, %26, %0;\n\t"  /* c_8 += hi(q, n_0) */
            "madc.lo.cc.u32 %1, %9, %28, %1;\n\t"  /* c_9 += lo(q, n_2) */
            "madc.hi.cc.u32 %2, %9, %28, %2;\n\t"  /* c_10 += hi(q, n_2) */
            "madc.lo.cc.u32 %3, %9, %30, %3;\n\t"  /* c_11 += lo(q, n_4) */
            "madc.hi.cc.u32 %4, %9, %30, %4;\n\t"  /* c_12 += hi(q, n_4) */
            "madc.lo.cc.u32 %5, %9, %32, %5;\n\t"  /* c_13 += lo(q, n_6) */
            "madc.hi.cc.u32 %6, %9, %32, %6;\n\t"  /* c_14 += hi(q, n_6) */
            "addc.cc.u32 %7, %7, 0;\n\t"  /* accum carry in dst_7 */
            "addc.u32    %8, %8, 0;\n\t"  /* accum carry in dst_8 */
            "mad.lo.cc.u32  %0, %9, %27, %0;\n\t"  /* c_1 += lo(q, n_1) */
            "madc.hi.cc.u32 %1, %9, %27, %1;\n\t"  /* c_2 += hi(q, n_1) */
            "madc.lo.cc.u32 %2, %9, %29, %2;\n\t"  /* c_3 += lo(q, n_3) */
            "madc.hi.cc.u32 %3, %9, %29, %3;\n\t"  /* c_4 += hi(q, n_3) */
            "madc.lo.cc.u32 %4, %9, %31, %4;\n\t"  /* c_5 += lo(q, n_5) */
            "madc.hi.cc.u32 %5, %9, %31, %5;\n\t"  /* c_6 += hi(q, n_5) */
            "madc.lo.cc.u32 %6, %9, %33, %6;\n\t"  /* c_7 += lo(q, n_7) */
            "madc.hi.cc.u32 %7, %9, %33, %7;\n\t"  /* c_8 += hi(q, n_7) */
            "addc.u32    %8, %8, 0;\n\t"  /* accum carry in dst_8 */
          
          /* Compute c_8..15 in the product a*b, storing the result in dst_0..7, with carry-out to dst_8 */
          "mad.hi.cc.u32  %0, %10, %25, %0;\n\t"  /* c_8 += hi(a_0, b_7) */
          "addc.cc.u32 %1, %1, 0;\n\t"  /* accum carry in c_9 */
          "addc.cc.u32 %2, %2, 0;\n\t"  /* accum carry in c_10 */
          "addc.cc.u32 %3, %3, 0;\n\t"  /* accum carry in c_11 */
          "addc.cc.u32 %4, %4, 0;\n\t"  /* accum carry in c_12 */
          "addc.cc.u32 %5, %5, 0;\n\t"  /* accum carry in c_13 */
          "addc.cc.u32 %6, %6, 0;\n\t"  /* accum carry in c_14 */
          "addc.cc.u32 %7, %7, 0;\n\t"  /* accum carry in c_15 */
          "addc.u32    %8, %8, 0;\n\t"  /* accum carry in c_16 */
          "mad.hi.cc.u32  %0, %11, %24, %0;\n\t"  /* c_8 += hi(a_1, b_6) */
          "addc.cc.u32 %1, %1, 0;\n\t"  /* accum carry in c_9 */
          "addc.cc.u32 %2, %2, 0;\n\t"  /* accum carry in c_10 */
          "addc.cc.u32 %3, %3, 0;\n\t"  /* accum carry in c_11 */
          "addc.cc.u32 %4, %4, 0;\n\t"  /* accum carry in c_12 */
          "addc.cc.u32 %5, %5, 0;\n\t"  /* accum carry in c_13 */
          "addc.cc.u32 %6, %6, 0;\n\t"  /* accum carry in c_14 */
          "addc.cc.u32 %7, %7, 0;\n\t"  /* accum carry in c_15 */
          "addc.u32    %8, %8, 0;\n\t"  /* accum carry in c_16 */
          "mad.lo.cc.u32  %0, %11, %25, %0;\n\t"  /* c_8 += lo(a_1, b_7) */
          "madc.hi.cc.u32 %1, %11, %25, %1;\n\t"  /* c_9 += hi(a_1, b_7) */
          "addc.cc.u32 %2, %2, 0;\n\t"  /* accum carry in c_10 */
          "addc.cc.u32 %3, %3, 0;\n\t"  /* accum carry in c_11 */
          "addc.cc.u32 %4, %4, 0;\n\t"  /* accum carry in c_12 */
          "addc.cc.u32 %5, %5, 0;\n\t"  /* accum carry in c_13 */
          "addc.cc.u32 %6, %6, 0;\n\t"  /* accum carry in c_14 */
          "addc.cc.u32 %7, %7, 0;\n\t"  /* accum carry in c_15 */
          "addc.u32    %8, %8, 0;\n\t"  /* accum carry in c_16 */
          "mad.lo.cc.u32  %0, %12, %24, %0;\n\t"  /* c_8 += lo(a_2, b_6) */
          "madc.hi.cc.u32 %1, %12, %24, %1;\n\t"  /* c_9 += hi(a_2, b_6) */
          "addc.cc.u32 %2, %2, 0;\n\t"  /* accum carry in c_10 */
          "addc.cc.u32 %3, %3, 0;\n\t"  /* accum carry in c_11 */
          "addc.cc.u32 %4, %4, 0;\n\t"  /* accum carry in c_12 */
          "addc.cc.u32 %5, %5, 0;\n\t"  /* accum carry in c_13 */
          "addc.cc.u32 %6, %6, 0;\n\t"  /* accum carry in c_14 */
          "addc.cc.u32 %7, %7, 0;\n\t"  /* accum carry in c_15 */
          "addc.u32    %8, %8, 0;\n\t"  /* accum carry in c_16 */
          "mad.hi.cc.u32  %0, %12, %23, %0;\n\t"  /* c_8 += hi(a_2, b_5) */
          "madc.lo.cc.u32 %1, %12, %25, %1;\n\t"  /* c_9 += lo(a_2, b_7) */
          "madc.hi.cc.u32 %2, %12, %25, %2;\n\t"  /* c_10 += hi(a_2, b_7) */
          "addc.cc.u32 %3, %3, 0;\n\t"  /* accum carry in c_11 */
          "addc.cc.u32 %4, %4, 0;\n\t"  /* accum carry in c_12 */
          "addc.cc.u32 %5, %5, 0;\n\t"  /* accum carry in c_13 */
          "addc.cc.u32 %6, %6, 0;\n\t"  /* accum carry in c_14 */
          "addc.cc.u32 %7, %7, 0;\n\t"  /* accum carry in c_15 */
          "addc.u32    %8, %8, 0;\n\t"  /* accum carry in c_16 */
          "mad.hi.cc.u32  %0, %13, %22, %0;\n\t"  /* c_8 += hi(a_3, b_4) */
          "madc.lo.cc.u32 %1, %13, %24, %1;\n\t"  /* c_9 += lo(a_3, b_6) */
          "madc.hi.cc.u32 %2, %13, %24, %2;\n\t"  /* c_10 += hi(a_3, b_6) */
          "addc.cc.u32 %3, %3, 0;\n\t"  /* accum carry in c_11 */
          "addc.cc.u32 %4, %4, 0;\n\t"  /* accum carry in c_12 */
          "addc.cc.u32 %5, %5, 0;\n\t"  /* accum carry in c_13 */
          "addc.cc.u32 %6, %6, 0;\n\t"  /* accum carry in c_14 */
          "addc.cc.u32 %7, %7, 0;\n\t"  /* accum carry in c_15 */
          "addc.u32    %8, %8, 0;\n\t"  /* accum carry in c_16 */
          "mad.lo.cc.u32  %0, %13, %23, %0;\n\t"  /* c_8 += lo(a_3, b_5) */
          "madc.hi.cc.u32 %1, %13, %23, %1;\n\t"  /* c_9 += hi(a_3, b_5) */
          "madc.lo.cc.u32 %2, %13, %25, %2;\n\t"  /* c_10 += lo(a_3, b_7) */
          "madc.hi.cc.u32 %3, %13, %25, %3;\n\t"  /* c_11 += hi(a_3, b_7) */
          "addc.cc.u32 %4, %4, 0;\n\t"  /* accum carry in c_12 */
          "addc.cc.u32 %5, %5, 0;\n\t"  /* accum carry in c_13 */
          "addc.cc.u32 %6, %6, 0;\n\t"  /* accum carry in c_14 */
          "addc.cc.u32 %7, %7, 0;\n\t"  /* accum carry in c_15 */
          "addc.u32    %8, %8, 0;\n\t"  /* accum carry in c_16 */
          "mad.lo.cc.u32  %0, %14, %22, %0;\n\t"  /* c_8 += lo(a_4, b_4) */
          "madc.hi.cc.u32 %1, %14, %22, %1;\n\t"  /* c_9 += hi(a_4, b_4) */
          "madc.lo.cc.u32 %2, %14, %24, %2;\n\t"  /* c_10 += lo(a_4, b_6) */
          "madc.hi.cc.u32 %3, %14, %24, %3;\n\t"  /* c_11 += hi(a_4, b_6) */
          "addc.cc.u32 %4, %4, 0;\n\t"  /* accum carry in c_12 */
          "addc.cc.u32 %5, %5, 0;\n\t"  /* accum carry in c_13 */
          "addc.cc.u32 %6, %6, 0;\n\t"  /* accum carry in c_14 */
          "addc.cc.u32 %7, %7, 0;\n\t"  /* accum carry in c_15 */
          "addc.u32    %8, %8, 0;\n\t"  /* accum carry in c_16 */
          "mad.hi.cc.u32  %0, %14, %21, %0;\n\t"  /* c_8 += hi(a_4, b_3) */
          "madc.lo.cc.u32 %1, %14, %23, %1;\n\t"  /* c_9 += lo(a_4, b_5) */
          "madc.hi.cc.u32 %2, %14, %23, %2;\n\t"  /* c_10 += hi(a_4, b_5) */
          "madc.lo.cc.u32 %3, %14, %25, %3;\n\t"  /* c_11 += lo(a_4, b_7) */
          "madc.hi.cc.u32 %4, %14, %25, %4;\n\t"  /* c_12 += hi(a_4, b_7) */
          "addc.cc.u32 %5, %5, 0;\n\t"  /* accum carry in c_13 */
          "addc.cc.u32 %6, %6, 0;\n\t"  /* accum carry in c_14 */
          "addc.cc.u32 %7, %7, 0;\n\t"  /* accum carry in c_15 */
          "addc.u32    %8, %8, 0;\n\t"  /* accum carry in c_16 */
          "mad.hi.cc.u32  %0, %15, %20, %0;\n\t"  /* c_8 += hi(a_5, b_2) */
          "madc.lo.cc.u32 %1, %15, %22, %1;\n\t"  /* c_9 += lo(a_5, b_4) */
          "madc.hi.cc.u32 %2, %15, %22, %2;\n\t"  /* c_10 += hi(a_5, b_4) */
          "madc.lo.cc.u32 %3, %15, %24, %3;\n\t"  /* c_11 += lo(a_5, b_6) */
          "madc.hi.cc.u32 %4, %15, %24, %4;\n\t"  /* c_12 += hi(a_5, b_6) */
          "addc.cc.u32 %5, %5, 0;\n\t"  /* accum carry in c_13 */
          "addc.cc.u32 %6, %6, 0;\n\t"  /* accum carry in c_14 */
          "addc.cc.u32 %7, %7, 0;\n\t"  /* accum carry in c_15 */
          "addc.u32    %8, %8, 0;\n\t"  /* accum carry in c_16 */
          "mad.lo.cc.u32  %0, %15, %21, %0;\n\t"  /* c_8 += lo(a_5, b_3) */
          "madc.hi.cc.u32 %1, %15, %21, %1;\n\t"  /* c_9 += hi(a_5, b_3) */
          "madc.lo.cc.u32 %2, %15, %23, %2;\n\t"  /* c_10 += lo(a_5, b_5) */
          "madc.hi.cc.u32 %3, %15, %23, %3;\n\t"  /* c_11 += hi(a_5, b_5) */
          "madc.lo.cc.u32 %4, %15, %25, %4;\n\t"  /* c_12 += lo(a_5, b_7) */
          "madc.hi.cc.u32 %5, %15, %25, %5;\n\t"  /* c_13 += hi(a_5, b_7) */
          "addc.cc.u32 %6, %6, 0;\n\t"  /* accum carry in c_14 */
          "addc.cc.u32 %7, %7, 0;\n\t"  /* accum carry in c_15 */
          "addc.u32    %8, %8, 0;\n\t"  /* accum carry in c_16 */
          "mad.lo.cc.u32  %0, %16, %20, %0;\n\t"  /* c_8 += lo(a_6, b_2) */
          "madc.hi.cc.u32 %1, %16, %20, %1;\n\t"  /* c_9 += hi(a_6, b_2) */
          "madc.lo.cc.u32 %2, %16, %22, %2;\n\t"  /* c_10 += lo(a_6, b_4) */
          "madc.hi.cc.u32 %3, %16, %22, %3;\n\t"  /* c_11 += hi(a_6, b_4) */
          "madc.lo.cc.u32 %4, %16, %24, %4;\n\t"  /* c_12 += lo(a_6, b_6) */
          "madc.hi.cc.u32 %5, %16, %24, %5;\n\t"  /* c_13 += hi(a_6, b_6) */
          "addc.cc.u32 %6, %6, 0;\n\t"  /* accum carry in c_14 */
          "addc.cc.u32 %7, %7, 0;\n\t"  /* accum carry in c_15 */
          "addc.u32    %8, %8, 0;\n\t"  /* accum carry in c_16 */
          "mad.hi.cc.u32  %0, %16, %19, %0;\n\t"  /* c_8 += hi(a_6, b_1) */
          "madc.lo.cc.u32 %1, %16, %21, %1;\n\t"  /* c_9 += lo(a_6, b_3) */
          "madc.hi.cc.u32 %2, %16, %21, %2;\n\t"  /* c_10 += hi(a_6, b_3) */
          "madc.lo.cc.u32 %3, %16, %23, %3;\n\t"  /* c_11 += lo(a_6, b_5) */
          "madc.hi.cc.u32 %4, %16, %23, %4;\n\t"  /* c_12 += hi(a_6, b_5) */
          "madc.lo.cc.u32 %5, %16, %25, %5;\n\t"  /* c_13 += lo(a_6, b_7) */
          "madc.hi.cc.u32 %6, %16, %25, %6;\n\t"  /* c_14 += hi(a_6, b_7) */
          "addc.cc.u32 %7, %7, 0;\n\t"  /* accum carry in c_15 */
          "addc.u32    %8, %8, 0;\n\t"  /* accum carry in c_16 */
          "mad.hi.cc.u32  %0, %17, %18, %0;\n\t"  /* c_8 += hi(a_7, b_0) */
          "madc.lo.cc.u32 %1, %17, %20, %1;\n\t"  /* c_9 += lo(a_7, b_2) */
          "madc.hi.cc.u32 %2, %17, %20, %2;\n\t"  /* c_10 += hi(a_7, b_2) */
          "madc.lo.cc.u32 %3, %17, %22, %3;\n\t"  /* c_11 += lo(a_7, b_4) */
          "madc.hi.cc.u32 %4, %17, %22, %4;\n\t"  /* c_12 += hi(a_7, b_4) */
          "madc.lo.cc.u32 %5, %17, %24, %5;\n\t"  /* c_13 += lo(a_7, b_6) */
          "madc.hi.cc.u32 %6, %17, %24, %6;\n\t"  /* c_14 += hi(a_7, b_6) */
          "addc.cc.u32 %7, %7, 0;\n\t"  /* accum carry in c_15 */
          "addc.u32    %8, %8, 0;\n\t"  /* accum carry in c_16 */
          "mad.lo.cc.u32  %0, %17, %19, %0;\n\t"  /* c_8 += lo(a_7, b_1) */
          "madc.hi.cc.u32 %1, %17, %19, %1;\n\t"  /* c_9 += hi(a_7, b_1) */
          "madc.lo.cc.u32 %2, %17, %21, %2;\n\t"  /* c_10 += lo(a_7, b_3) */
          "madc.hi.cc.u32 %3, %17, %21, %3;\n\t"  /* c_11 += hi(a_7, b_3) */
          "madc.lo.cc.u32 %4, %17, %23, %4;\n\t"  /* c_12 += lo(a_7, b_5) */
          "madc.hi.cc.u32 %5, %17, %23, %5;\n\t"  /* c_13 += hi(a_7, b_5) */
          "madc.lo.cc.u32 %6, %17, %25, %6;\n\t"  /* c_14 += lo(a_7, b_7) */
          "madc.hi.cc.u32 %7, %17, %25, %7;\n\t"  /* c_15 += hi(a_7, b_7) */
          "addc.u32    %8, %8, 0;\n\t"  /* accum carry in c_16 */
          
          : "+r" (dst->x[0]), "+r" (dst->x[1]), "+r" (dst->x[2]), "+r" (dst->x[3]), "+r" (dst->x[4]), "+r" (dst->x[5]), "+r" (dst->x[6]), "+r" (dst->x[7]), "+r" (dst_8), "+r" (q)
          : "r" (src1->x[0]), "r" (src1->x[1]), "r" (src1->x[2]), "r" (src1->x[3]), "r" (src1->x[4]), "r" (src1->x[5]), "r" (src1->x[6]), "r" (src1->x[7]), 
            "r" (src2->x[0]), "r" (src2->x[1]), "r" (src2->x[2]), "r" (src2->x[3]), "r" (src2->x[4]), "r" (src2->x[5]), "r" (src2->x[6]), "r" (src2->x[7]), 
            "r" (n->n->x[0]), "r" (n->n->x[1]), "r" (n->n->x[2]), "r" (n->n->x[3]), "r" (n->n->x[4]), "r" (n->n->x[5]), "r" (n->n->x[6]), "r" (n->n->x[7]), 
            "r" (n->np)
        );
        
        /* Reduce as needed */
        if (dst_8 || (ul256_cmp(dst, n->n) >= 0))
            ul256_sub(dst, dst, n->n);
        ul256_set(_dst, dst);
    #else
        /* The pairwise products of the a_i and b_j */
        const uint64_t a_0__b_0 = ((uint64_t)_src1->x[0]) * ((uint64_t)_src2->x[0]);
        const uint32_t a_0__b_0_lo = a_0__b_0;
        const uint32_t a_0__b_0_hi = a_0__b_0 >> 32;
        const uint64_t a_0__b_1 = ((uint64_t)_src1->x[0]) * ((uint64_t)_src2->x[1]);
        const uint32_t a_0__b_1_lo = a_0__b_1;
        const uint32_t a_0__b_1_hi = a_0__b_1 >> 32;
        const uint64_t a_0__b_2 = ((uint64_t)_src1->x[0]) * ((uint64_t)_src2->x[2]);
        const uint32_t a_0__b_2_lo = a_0__b_2;
        const uint32_t a_0__b_2_hi = a_0__b_2 >> 32;
        const uint64_t a_0__b_3 = ((uint64_t)_src1->x[0]) * ((uint64_t)_src2->x[3]);
        const uint32_t a_0__b_3_lo = a_0__b_3;
        const uint32_t a_0__b_3_hi = a_0__b_3 >> 32;
        const uint64_t a_0__b_4 = ((uint64_t)_src1->x[0]) * ((uint64_t)_src2->x[4]);
        const uint32_t a_0__b_4_lo = a_0__b_4;
        const uint32_t a_0__b_4_hi = a_0__b_4 >> 32;
        const uint64_t a_0__b_5 = ((uint64_t)_src1->x[0]) * ((uint64_t)_src2->x[5]);
        const uint32_t a_0__b_5_lo = a_0__b_5;
        const uint32_t a_0__b_5_hi = a_0__b_5 >> 32;
        const uint64_t a_0__b_6 = ((uint64_t)_src1->x[0]) * ((uint64_t)_src2->x[6]);
        const uint32_t a_0__b_6_lo = a_0__b_6;
        const uint32_t a_0__b_6_hi = a_0__b_6 >> 32;
        const uint64_t a_0__b_7 = ((uint64_t)_src1->x[0]) * ((uint64_t)_src2->x[7]);
        const uint32_t a_0__b_7_lo = a_0__b_7;
        const uint32_t a_0__b_7_hi = a_0__b_7 >> 32;
        const uint64_t a_1__b_0 = ((uint64_t)_src1->x[1]) * ((uint64_t)_src2->x[0]);
        const uint32_t a_1__b_0_lo = a_1__b_0;
        const uint32_t a_1__b_0_hi = a_1__b_0 >> 32;
        const uint64_t a_1__b_1 = ((uint64_t)_src1->x[1]) * ((uint64_t)_src2->x[1]);
        const uint32_t a_1__b_1_lo = a_1__b_1;
        const uint32_t a_1__b_1_hi = a_1__b_1 >> 32;
        const uint64_t a_1__b_2 = ((uint64_t)_src1->x[1]) * ((uint64_t)_src2->x[2]);
        const uint32_t a_1__b_2_lo = a_1__b_2;
        const uint32_t a_1__b_2_hi = a_1__b_2 >> 32;
        const uint64_t a_1__b_3 = ((uint64_t)_src1->x[1]) * ((uint64_t)_src2->x[3]);
        const uint32_t a_1__b_3_lo = a_1__b_3;
        const uint32_t a_1__b_3_hi = a_1__b_3 >> 32;
        const uint64_t a_1__b_4 = ((uint64_t)_src1->x[1]) * ((uint64_t)_src2->x[4]);
        const uint32_t a_1__b_4_lo = a_1__b_4;
        const uint32_t a_1__b_4_hi = a_1__b_4 >> 32;
        const uint64_t a_1__b_5 = ((uint64_t)_src1->x[1]) * ((uint64_t)_src2->x[5]);
        const uint32_t a_1__b_5_lo = a_1__b_5;
        const uint32_t a_1__b_5_hi = a_1__b_5 >> 32;
        const uint64_t a_1__b_6 = ((uint64_t)_src1->x[1]) * ((uint64_t)_src2->x[6]);
        const uint32_t a_1__b_6_lo = a_1__b_6;
        const uint32_t a_1__b_6_hi = a_1__b_6 >> 32;
        const uint64_t a_1__b_7 = ((uint64_t)_src1->x[1]) * ((uint64_t)_src2->x[7]);
        const uint32_t a_1__b_7_lo = a_1__b_7;
        const uint32_t a_1__b_7_hi = a_1__b_7 >> 32;
        const uint64_t a_2__b_0 = ((uint64_t)_src1->x[2]) * ((uint64_t)_src2->x[0]);
        const uint32_t a_2__b_0_lo = a_2__b_0;
        const uint32_t a_2__b_0_hi = a_2__b_0 >> 32;
        const uint64_t a_2__b_1 = ((uint64_t)_src1->x[2]) * ((uint64_t)_src2->x[1]);
        const uint32_t a_2__b_1_lo = a_2__b_1;
        const uint32_t a_2__b_1_hi = a_2__b_1 >> 32;
        const uint64_t a_2__b_2 = ((uint64_t)_src1->x[2]) * ((uint64_t)_src2->x[2]);
        const uint32_t a_2__b_2_lo = a_2__b_2;
        const uint32_t a_2__b_2_hi = a_2__b_2 >> 32;
        const uint64_t a_2__b_3 = ((uint64_t)_src1->x[2]) * ((uint64_t)_src2->x[3]);
        const uint32_t a_2__b_3_lo = a_2__b_3;
        const uint32_t a_2__b_3_hi = a_2__b_3 >> 32;
        const uint64_t a_2__b_4 = ((uint64_t)_src1->x[2]) * ((uint64_t)_src2->x[4]);
        const uint32_t a_2__b_4_lo = a_2__b_4;
        const uint32_t a_2__b_4_hi = a_2__b_4 >> 32;
        const uint64_t a_2__b_5 = ((uint64_t)_src1->x[2]) * ((uint64_t)_src2->x[5]);
        const uint32_t a_2__b_5_lo = a_2__b_5;
        const uint32_t a_2__b_5_hi = a_2__b_5 >> 32;
        const uint64_t a_2__b_6 = ((uint64_t)_src1->x[2]) * ((uint64_t)_src2->x[6]);
        const uint32_t a_2__b_6_lo = a_2__b_6;
        const uint32_t a_2__b_6_hi = a_2__b_6 >> 32;
        const uint64_t a_2__b_7 = ((uint64_t)_src1->x[2]) * ((uint64_t)_src2->x[7]);
        const uint32_t a_2__b_7_lo = a_2__b_7;
        const uint32_t a_2__b_7_hi = a_2__b_7 >> 32;
        const uint64_t a_3__b_0 = ((uint64_t)_src1->x[3]) * ((uint64_t)_src2->x[0]);
        const uint32_t a_3__b_0_lo = a_3__b_0;
        const uint32_t a_3__b_0_hi = a_3__b_0 >> 32;
        const uint64_t a_3__b_1 = ((uint64_t)_src1->x[3]) * ((uint64_t)_src2->x[1]);
        const uint32_t a_3__b_1_lo = a_3__b_1;
        const uint32_t a_3__b_1_hi = a_3__b_1 >> 32;
        const uint64_t a_3__b_2 = ((uint64_t)_src1->x[3]) * ((uint64_t)_src2->x[2]);
        const uint32_t a_3__b_2_lo = a_3__b_2;
        const uint32_t a_3__b_2_hi = a_3__b_2 >> 32;
        const uint64_t a_3__b_3 = ((uint64_t)_src1->x[3]) * ((uint64_t)_src2->x[3]);
        const uint32_t a_3__b_3_lo = a_3__b_3;
        const uint32_t a_3__b_3_hi = a_3__b_3 >> 32;
        const uint64_t a_3__b_4 = ((uint64_t)_src1->x[3]) * ((uint64_t)_src2->x[4]);
        const uint32_t a_3__b_4_lo = a_3__b_4;
        const uint32_t a_3__b_4_hi = a_3__b_4 >> 32;
        const uint64_t a_3__b_5 = ((uint64_t)_src1->x[3]) * ((uint64_t)_src2->x[5]);
        const uint32_t a_3__b_5_lo = a_3__b_5;
        const uint32_t a_3__b_5_hi = a_3__b_5 >> 32;
        const uint64_t a_3__b_6 = ((uint64_t)_src1->x[3]) * ((uint64_t)_src2->x[6]);
        const uint32_t a_3__b_6_lo = a_3__b_6;
        const uint32_t a_3__b_6_hi = a_3__b_6 >> 32;
        const uint64_t a_3__b_7 = ((uint64_t)_src1->x[3]) * ((uint64_t)_src2->x[7]);
        const uint32_t a_3__b_7_lo = a_3__b_7;
        const uint32_t a_3__b_7_hi = a_3__b_7 >> 32;
        const uint64_t a_4__b_0 = ((uint64_t)_src1->x[4]) * ((uint64_t)_src2->x[0]);
        const uint32_t a_4__b_0_lo = a_4__b_0;
        const uint32_t a_4__b_0_hi = a_4__b_0 >> 32;
        const uint64_t a_4__b_1 = ((uint64_t)_src1->x[4]) * ((uint64_t)_src2->x[1]);
        const uint32_t a_4__b_1_lo = a_4__b_1;
        const uint32_t a_4__b_1_hi = a_4__b_1 >> 32;
        const uint64_t a_4__b_2 = ((uint64_t)_src1->x[4]) * ((uint64_t)_src2->x[2]);
        const uint32_t a_4__b_2_lo = a_4__b_2;
        const uint32_t a_4__b_2_hi = a_4__b_2 >> 32;
        const uint64_t a_4__b_3 = ((uint64_t)_src1->x[4]) * ((uint64_t)_src2->x[3]);
        const uint32_t a_4__b_3_lo = a_4__b_3;
        const uint32_t a_4__b_3_hi = a_4__b_3 >> 32;
        const uint64_t a_4__b_4 = ((uint64_t)_src1->x[4]) * ((uint64_t)_src2->x[4]);
        const uint32_t a_4__b_4_lo = a_4__b_4;
        const uint32_t a_4__b_4_hi = a_4__b_4 >> 32;
        const uint64_t a_4__b_5 = ((uint64_t)_src1->x[4]) * ((uint64_t)_src2->x[5]);
        const uint32_t a_4__b_5_lo = a_4__b_5;
        const uint32_t a_4__b_5_hi = a_4__b_5 >> 32;
        const uint64_t a_4__b_6 = ((uint64_t)_src1->x[4]) * ((uint64_t)_src2->x[6]);
        const uint32_t a_4__b_6_lo = a_4__b_6;
        const uint32_t a_4__b_6_hi = a_4__b_6 >> 32;
        const uint64_t a_4__b_7 = ((uint64_t)_src1->x[4]) * ((uint64_t)_src2->x[7]);
        const uint32_t a_4__b_7_lo = a_4__b_7;
        const uint32_t a_4__b_7_hi = a_4__b_7 >> 32;
        const uint64_t a_5__b_0 = ((uint64_t)_src1->x[5]) * ((uint64_t)_src2->x[0]);
        const uint32_t a_5__b_0_lo = a_5__b_0;
        const uint32_t a_5__b_0_hi = a_5__b_0 >> 32;
        const uint64_t a_5__b_1 = ((uint64_t)_src1->x[5]) * ((uint64_t)_src2->x[1]);
        const uint32_t a_5__b_1_lo = a_5__b_1;
        const uint32_t a_5__b_1_hi = a_5__b_1 >> 32;
        const uint64_t a_5__b_2 = ((uint64_t)_src1->x[5]) * ((uint64_t)_src2->x[2]);
        const uint32_t a_5__b_2_lo = a_5__b_2;
        const uint32_t a_5__b_2_hi = a_5__b_2 >> 32;
        const uint64_t a_5__b_3 = ((uint64_t)_src1->x[5]) * ((uint64_t)_src2->x[3]);
        const uint32_t a_5__b_3_lo = a_5__b_3;
        const uint32_t a_5__b_3_hi = a_5__b_3 >> 32;
        const uint64_t a_5__b_4 = ((uint64_t)_src1->x[5]) * ((uint64_t)_src2->x[4]);
        const uint32_t a_5__b_4_lo = a_5__b_4;
        const uint32_t a_5__b_4_hi = a_5__b_4 >> 32;
        const uint64_t a_5__b_5 = ((uint64_t)_src1->x[5]) * ((uint64_t)_src2->x[5]);
        const uint32_t a_5__b_5_lo = a_5__b_5;
        const uint32_t a_5__b_5_hi = a_5__b_5 >> 32;
        const uint64_t a_5__b_6 = ((uint64_t)_src1->x[5]) * ((uint64_t)_src2->x[6]);
        const uint32_t a_5__b_6_lo = a_5__b_6;
        const uint32_t a_5__b_6_hi = a_5__b_6 >> 32;
        const uint64_t a_5__b_7 = ((uint64_t)_src1->x[5]) * ((uint64_t)_src2->x[7]);
        const uint32_t a_5__b_7_lo = a_5__b_7;
        const uint32_t a_5__b_7_hi = a_5__b_7 >> 32;
        const uint64_t a_6__b_0 = ((uint64_t)_src1->x[6]) * ((uint64_t)_src2->x[0]);
        const uint32_t a_6__b_0_lo = a_6__b_0;
        const uint32_t a_6__b_0_hi = a_6__b_0 >> 32;
        const uint64_t a_6__b_1 = ((uint64_t)_src1->x[6]) * ((uint64_t)_src2->x[1]);
        const uint32_t a_6__b_1_lo = a_6__b_1;
        const uint32_t a_6__b_1_hi = a_6__b_1 >> 32;
        const uint64_t a_6__b_2 = ((uint64_t)_src1->x[6]) * ((uint64_t)_src2->x[2]);
        const uint32_t a_6__b_2_lo = a_6__b_2;
        const uint32_t a_6__b_2_hi = a_6__b_2 >> 32;
        const uint64_t a_6__b_3 = ((uint64_t)_src1->x[6]) * ((uint64_t)_src2->x[3]);
        const uint32_t a_6__b_3_lo = a_6__b_3;
        const uint32_t a_6__b_3_hi = a_6__b_3 >> 32;
        const uint64_t a_6__b_4 = ((uint64_t)_src1->x[6]) * ((uint64_t)_src2->x[4]);
        const uint32_t a_6__b_4_lo = a_6__b_4;
        const uint32_t a_6__b_4_hi = a_6__b_4 >> 32;
        const uint64_t a_6__b_5 = ((uint64_t)_src1->x[6]) * ((uint64_t)_src2->x[5]);
        const uint32_t a_6__b_5_lo = a_6__b_5;
        const uint32_t a_6__b_5_hi = a_6__b_5 >> 32;
        const uint64_t a_6__b_6 = ((uint64_t)_src1->x[6]) * ((uint64_t)_src2->x[6]);
        const uint32_t a_6__b_6_lo = a_6__b_6;
        const uint32_t a_6__b_6_hi = a_6__b_6 >> 32;
        const uint64_t a_6__b_7 = ((uint64_t)_src1->x[6]) * ((uint64_t)_src2->x[7]);
        const uint32_t a_6__b_7_lo = a_6__b_7;
        const uint32_t a_6__b_7_hi = a_6__b_7 >> 32;
        const uint64_t a_7__b_0 = ((uint64_t)_src1->x[7]) * ((uint64_t)_src2->x[0]);
        const uint32_t a_7__b_0_lo = a_7__b_0;
        const uint32_t a_7__b_0_hi = a_7__b_0 >> 32;
        const uint64_t a_7__b_1 = ((uint64_t)_src1->x[7]) * ((uint64_t)_src2->x[1]);
        const uint32_t a_7__b_1_lo = a_7__b_1;
        const uint32_t a_7__b_1_hi = a_7__b_1 >> 32;
        const uint64_t a_7__b_2 = ((uint64_t)_src1->x[7]) * ((uint64_t)_src2->x[2]);
        const uint32_t a_7__b_2_lo = a_7__b_2;
        const uint32_t a_7__b_2_hi = a_7__b_2 >> 32;
        const uint64_t a_7__b_3 = ((uint64_t)_src1->x[7]) * ((uint64_t)_src2->x[3]);
        const uint32_t a_7__b_3_lo = a_7__b_3;
        const uint32_t a_7__b_3_hi = a_7__b_3 >> 32;
        const uint64_t a_7__b_4 = ((uint64_t)_src1->x[7]) * ((uint64_t)_src2->x[4]);
        const uint32_t a_7__b_4_lo = a_7__b_4;
        const uint32_t a_7__b_4_hi = a_7__b_4 >> 32;
        const uint64_t a_7__b_5 = ((uint64_t)_src1->x[7]) * ((uint64_t)_src2->x[5]);
        const uint32_t a_7__b_5_lo = a_7__b_5;
        const uint32_t a_7__b_5_hi = a_7__b_5 >> 32;
        const uint64_t a_7__b_6 = ((uint64_t)_src1->x[7]) * ((uint64_t)_src2->x[6]);
        const uint32_t a_7__b_6_lo = a_7__b_6;
        const uint32_t a_7__b_6_hi = a_7__b_6 >> 32;
        const uint64_t a_7__b_7 = ((uint64_t)_src1->x[7]) * ((uint64_t)_src2->x[7]);
        const uint32_t a_7__b_7_lo = a_7__b_7;
        const uint32_t a_7__b_7_hi = a_7__b_7 >> 32;
        
        /* Limbs of the product C = A*B */
        uint32_t q_0 = 0;
        uint32_t q_1 = 0;
        uint32_t q_2 = 0;
        uint32_t q_3 = 0;
        uint32_t q_4 = 0;
        uint32_t q_5 = 0;
        uint32_t q_6 = 0;
        uint32_t q_7 = 0;
        uint32_t c_0 = 0;
        uint32_t c_1 = 0;
        uint32_t c_2 = 0;
        uint32_t c_3 = 0;
        uint32_t c_4 = 0;
        uint32_t c_5 = 0;
        uint32_t c_6 = 0;
        uint32_t c_7 = 0;
        uint32_t c_8 = 0;
        uint32_t c_9 = 0;
        uint32_t c_10 = 0;
        uint32_t c_11 = 0;
        uint32_t c_12 = 0;
        uint32_t c_13 = 0;
        uint32_t c_14 = 0;
        uint32_t c_15 = 0;
        uint32_t c_16 = 0;
        
        /* The product of the q_i's with N */
        uint64_t q_0__N_0 = 0;
        uint64_t q_0__N_1 = 0;
        uint64_t q_0__N_2 = 0;
        uint64_t q_0__N_3 = 0;
        uint64_t q_0__N_4 = 0;
        uint64_t q_0__N_5 = 0;
        uint64_t q_0__N_6 = 0;
        uint64_t q_0__N_7 = 0;
        uint64_t q_1__N_0 = 0;
        uint64_t q_1__N_1 = 0;
        uint64_t q_1__N_2 = 0;
        uint64_t q_1__N_3 = 0;
        uint64_t q_1__N_4 = 0;
        uint64_t q_1__N_5 = 0;
        uint64_t q_1__N_6 = 0;
        uint64_t q_1__N_7 = 0;
        uint64_t q_2__N_0 = 0;
        uint64_t q_2__N_1 = 0;
        uint64_t q_2__N_2 = 0;
        uint64_t q_2__N_3 = 0;
        uint64_t q_2__N_4 = 0;
        uint64_t q_2__N_5 = 0;
        uint64_t q_2__N_6 = 0;
        uint64_t q_2__N_7 = 0;
        uint64_t q_3__N_0 = 0;
        uint64_t q_3__N_1 = 0;
        uint64_t q_3__N_2 = 0;
        uint64_t q_3__N_3 = 0;
        uint64_t q_3__N_4 = 0;
        uint64_t q_3__N_5 = 0;
        uint64_t q_3__N_6 = 0;
        uint64_t q_3__N_7 = 0;
        uint64_t q_4__N_0 = 0;
        uint64_t q_4__N_1 = 0;
        uint64_t q_4__N_2 = 0;
        uint64_t q_4__N_3 = 0;
        uint64_t q_4__N_4 = 0;
        uint64_t q_4__N_5 = 0;
        uint64_t q_4__N_6 = 0;
        uint64_t q_4__N_7 = 0;
        uint64_t q_5__N_0 = 0;
        uint64_t q_5__N_1 = 0;
        uint64_t q_5__N_2 = 0;
        uint64_t q_5__N_3 = 0;
        uint64_t q_5__N_4 = 0;
        uint64_t q_5__N_5 = 0;
        uint64_t q_5__N_6 = 0;
        uint64_t q_5__N_7 = 0;
        uint64_t q_6__N_0 = 0;
        uint64_t q_6__N_1 = 0;
        uint64_t q_6__N_2 = 0;
        uint64_t q_6__N_3 = 0;
        uint64_t q_6__N_4 = 0;
        uint64_t q_6__N_5 = 0;
        uint64_t q_6__N_6 = 0;
        uint64_t q_6__N_7 = 0;
        uint64_t q_7__N_0 = 0;
        uint64_t q_7__N_1 = 0;
        uint64_t q_7__N_2 = 0;
        uint64_t q_7__N_3 = 0;
        uint64_t q_7__N_4 = 0;
        uint64_t q_7__N_5 = 0;
        uint64_t q_7__N_6 = 0;
        uint64_t q_7__N_7 = 0;
        
        /* Compute c_0 */
        {
            /* Add the product terms into c_0, accumulating carries in c_1 */
            c_1 += ul32_addc(&c_0, &c_0, &a_0__b_0_lo);
            
            /* Add the q_i*N's for i < 0 */
            
            /* Compute q_0 and add its product with N */
            q_0 = n->np * c_0;
            q_0__N_0 = ((uint64_t)q_0) * ((uint64_t)n->n->x[0]);
            q_0__N_1 = ((uint64_t)q_0) * ((uint64_t)n->n->x[1]);
            q_0__N_2 = ((uint64_t)q_0) * ((uint64_t)n->n->x[2]);
            q_0__N_3 = ((uint64_t)q_0) * ((uint64_t)n->n->x[3]);
            q_0__N_4 = ((uint64_t)q_0) * ((uint64_t)n->n->x[4]);
            q_0__N_5 = ((uint64_t)q_0) * ((uint64_t)n->n->x[5]);
            q_0__N_6 = ((uint64_t)q_0) * ((uint64_t)n->n->x[6]);
            q_0__N_7 = ((uint64_t)q_0) * ((uint64_t)n->n->x[7]);
            const uint32_t q_0__N_0_lo = q_0__N_0;
            c_1 += ul32_addc(&c_0, &c_0, &q_0__N_0_lo);
        }
        
        /* Compute c_1 */
        {
            /* Add the product terms into c_1, accumulating carries in c_2 */
            c_2 += ul32_addc(&c_1, &c_1, &a_0__b_0_hi);
            c_2 += ul32_addc(&c_1, &c_1, &a_0__b_1_lo);
            c_2 += ul32_addc(&c_1, &c_1, &a_1__b_0_lo);
            
            /* Add the q_i*N's for i < 1 */
            const uint32_t q_0__N_1_lo = q_0__N_1;
            c_2 += ul32_addc(&c_1, &c_1, &q_0__N_1_lo);
            const uint32_t q_0__N_0_hi = q_0__N_0 >> 32;
            c_2 += ul32_addc(&c_1, &c_1, &q_0__N_0_hi);
            
            /* Compute q_1 and add its product with N */
            q_1 = n->np * c_1;
            q_1__N_0 = ((uint64_t)q_1) * ((uint64_t)n->n->x[0]);
            q_1__N_1 = ((uint64_t)q_1) * ((uint64_t)n->n->x[1]);
            q_1__N_2 = ((uint64_t)q_1) * ((uint64_t)n->n->x[2]);
            q_1__N_3 = ((uint64_t)q_1) * ((uint64_t)n->n->x[3]);
            q_1__N_4 = ((uint64_t)q_1) * ((uint64_t)n->n->x[4]);
            q_1__N_5 = ((uint64_t)q_1) * ((uint64_t)n->n->x[5]);
            q_1__N_6 = ((uint64_t)q_1) * ((uint64_t)n->n->x[6]);
            q_1__N_7 = ((uint64_t)q_1) * ((uint64_t)n->n->x[7]);
            const uint32_t q_1__N_0_lo = q_1__N_0;
            c_2 += ul32_addc(&c_1, &c_1, &q_1__N_0_lo);
        }
        
        /* Compute c_2 */
        {
            /* Add the product terms into c_2, accumulating carries in c_3 */
            c_3 += ul32_addc(&c_2, &c_2, &a_0__b_1_hi);
            c_3 += ul32_addc(&c_2, &c_2, &a_0__b_2_lo);
            c_3 += ul32_addc(&c_2, &c_2, &a_1__b_0_hi);
            c_3 += ul32_addc(&c_2, &c_2, &a_1__b_1_lo);
            c_3 += ul32_addc(&c_2, &c_2, &a_2__b_0_lo);
            
            /* Add the q_i*N's for i < 2 */
            const uint32_t q_0__N_2_lo = q_0__N_2;
            c_3 += ul32_addc(&c_2, &c_2, &q_0__N_2_lo);
            const uint32_t q_0__N_1_hi = q_0__N_1 >> 32;
            c_3 += ul32_addc(&c_2, &c_2, &q_0__N_1_hi);
            const uint32_t q_1__N_1_lo = q_1__N_1;
            c_3 += ul32_addc(&c_2, &c_2, &q_1__N_1_lo);
            const uint32_t q_1__N_0_hi = q_1__N_0 >> 32;
            c_3 += ul32_addc(&c_2, &c_2, &q_1__N_0_hi);
            
            /* Compute q_2 and add its product with N */
            q_2 = n->np * c_2;
            q_2__N_0 = ((uint64_t)q_2) * ((uint64_t)n->n->x[0]);
            q_2__N_1 = ((uint64_t)q_2) * ((uint64_t)n->n->x[1]);
            q_2__N_2 = ((uint64_t)q_2) * ((uint64_t)n->n->x[2]);
            q_2__N_3 = ((uint64_t)q_2) * ((uint64_t)n->n->x[3]);
            q_2__N_4 = ((uint64_t)q_2) * ((uint64_t)n->n->x[4]);
            q_2__N_5 = ((uint64_t)q_2) * ((uint64_t)n->n->x[5]);
            q_2__N_6 = ((uint64_t)q_2) * ((uint64_t)n->n->x[6]);
            q_2__N_7 = ((uint64_t)q_2) * ((uint64_t)n->n->x[7]);
            const uint32_t q_2__N_0_lo = q_2__N_0;
            c_3 += ul32_addc(&c_2, &c_2, &q_2__N_0_lo);
        }
        
        /* Compute c_3 */
        {
            /* Add the product terms into c_3, accumulating carries in c_4 */
            c_4 += ul32_addc(&c_3, &c_3, &a_0__b_2_hi);
            c_4 += ul32_addc(&c_3, &c_3, &a_0__b_3_lo);
            c_4 += ul32_addc(&c_3, &c_3, &a_1__b_1_hi);
            c_4 += ul32_addc(&c_3, &c_3, &a_1__b_2_lo);
            c_4 += ul32_addc(&c_3, &c_3, &a_2__b_0_hi);
            c_4 += ul32_addc(&c_3, &c_3, &a_2__b_1_lo);
            c_4 += ul32_addc(&c_3, &c_3, &a_3__b_0_lo);
            
            /* Add the q_i*N's for i < 3 */
            const uint32_t q_0__N_3_lo = q_0__N_3;
            c_4 += ul32_addc(&c_3, &c_3, &q_0__N_3_lo);
            const uint32_t q_0__N_2_hi = q_0__N_2 >> 32;
            c_4 += ul32_addc(&c_3, &c_3, &q_0__N_2_hi);
            const uint32_t q_1__N_2_lo = q_1__N_2;
            c_4 += ul32_addc(&c_3, &c_3, &q_1__N_2_lo);
            const uint32_t q_1__N_1_hi = q_1__N_1 >> 32;
            c_4 += ul32_addc(&c_3, &c_3, &q_1__N_1_hi);
            const uint32_t q_2__N_1_lo = q_2__N_1;
            c_4 += ul32_addc(&c_3, &c_3, &q_2__N_1_lo);
            const uint32_t q_2__N_0_hi = q_2__N_0 >> 32;
            c_4 += ul32_addc(&c_3, &c_3, &q_2__N_0_hi);
            
            /* Compute q_3 and add its product with N */
            q_3 = n->np * c_3;
            q_3__N_0 = ((uint64_t)q_3) * ((uint64_t)n->n->x[0]);
            q_3__N_1 = ((uint64_t)q_3) * ((uint64_t)n->n->x[1]);
            q_3__N_2 = ((uint64_t)q_3) * ((uint64_t)n->n->x[2]);
            q_3__N_3 = ((uint64_t)q_3) * ((uint64_t)n->n->x[3]);
            q_3__N_4 = ((uint64_t)q_3) * ((uint64_t)n->n->x[4]);
            q_3__N_5 = ((uint64_t)q_3) * ((uint64_t)n->n->x[5]);
            q_3__N_6 = ((uint64_t)q_3) * ((uint64_t)n->n->x[6]);
            q_3__N_7 = ((uint64_t)q_3) * ((uint64_t)n->n->x[7]);
            const uint32_t q_3__N_0_lo = q_3__N_0;
            c_4 += ul32_addc(&c_3, &c_3, &q_3__N_0_lo);
        }
        
        /* Compute c_4 */
        {
            /* Add the product terms into c_4, accumulating carries in c_5 */
            c_5 += ul32_addc(&c_4, &c_4, &a_0__b_3_hi);
            c_5 += ul32_addc(&c_4, &c_4, &a_0__b_4_lo);
            c_5 += ul32_addc(&c_4, &c_4, &a_1__b_2_hi);
            c_5 += ul32_addc(&c_4, &c_4, &a_1__b_3_lo);
            c_5 += ul32_addc(&c_4, &c_4, &a_2__b_1_hi);
            c_5 += ul32_addc(&c_4, &c_4, &a_2__b_2_lo);
            c_5 += ul32_addc(&c_4, &c_4, &a_3__b_0_hi);
            c_5 += ul32_addc(&c_4, &c_4, &a_3__b_1_lo);
            c_5 += ul32_addc(&c_4, &c_4, &a_4__b_0_lo);
            
            /* Add the q_i*N's for i < 4 */
            const uint32_t q_0__N_4_lo = q_0__N_4;
            c_5 += ul32_addc(&c_4, &c_4, &q_0__N_4_lo);
            const uint32_t q_0__N_3_hi = q_0__N_3 >> 32;
            c_5 += ul32_addc(&c_4, &c_4, &q_0__N_3_hi);
            const uint32_t q_1__N_3_lo = q_1__N_3;
            c_5 += ul32_addc(&c_4, &c_4, &q_1__N_3_lo);
            const uint32_t q_1__N_2_hi = q_1__N_2 >> 32;
            c_5 += ul32_addc(&c_4, &c_4, &q_1__N_2_hi);
            const uint32_t q_2__N_2_lo = q_2__N_2;
            c_5 += ul32_addc(&c_4, &c_4, &q_2__N_2_lo);
            const uint32_t q_2__N_1_hi = q_2__N_1 >> 32;
            c_5 += ul32_addc(&c_4, &c_4, &q_2__N_1_hi);
            const uint32_t q_3__N_1_lo = q_3__N_1;
            c_5 += ul32_addc(&c_4, &c_4, &q_3__N_1_lo);
            const uint32_t q_3__N_0_hi = q_3__N_0 >> 32;
            c_5 += ul32_addc(&c_4, &c_4, &q_3__N_0_hi);
            
            /* Compute q_4 and add its product with N */
            q_4 = n->np * c_4;
            q_4__N_0 = ((uint64_t)q_4) * ((uint64_t)n->n->x[0]);
            q_4__N_1 = ((uint64_t)q_4) * ((uint64_t)n->n->x[1]);
            q_4__N_2 = ((uint64_t)q_4) * ((uint64_t)n->n->x[2]);
            q_4__N_3 = ((uint64_t)q_4) * ((uint64_t)n->n->x[3]);
            q_4__N_4 = ((uint64_t)q_4) * ((uint64_t)n->n->x[4]);
            q_4__N_5 = ((uint64_t)q_4) * ((uint64_t)n->n->x[5]);
            q_4__N_6 = ((uint64_t)q_4) * ((uint64_t)n->n->x[6]);
            q_4__N_7 = ((uint64_t)q_4) * ((uint64_t)n->n->x[7]);
            const uint32_t q_4__N_0_lo = q_4__N_0;
            c_5 += ul32_addc(&c_4, &c_4, &q_4__N_0_lo);
        }
        
        /* Compute c_5 */
        {
            /* Add the product terms into c_5, accumulating carries in c_6 */
            c_6 += ul32_addc(&c_5, &c_5, &a_0__b_4_hi);
            c_6 += ul32_addc(&c_5, &c_5, &a_0__b_5_lo);
            c_6 += ul32_addc(&c_5, &c_5, &a_1__b_3_hi);
            c_6 += ul32_addc(&c_5, &c_5, &a_1__b_4_lo);
            c_6 += ul32_addc(&c_5, &c_5, &a_2__b_2_hi);
            c_6 += ul32_addc(&c_5, &c_5, &a_2__b_3_lo);
            c_6 += ul32_addc(&c_5, &c_5, &a_3__b_1_hi);
            c_6 += ul32_addc(&c_5, &c_5, &a_3__b_2_lo);
            c_6 += ul32_addc(&c_5, &c_5, &a_4__b_0_hi);
            c_6 += ul32_addc(&c_5, &c_5, &a_4__b_1_lo);
            c_6 += ul32_addc(&c_5, &c_5, &a_5__b_0_lo);
            
            /* Add the q_i*N's for i < 5 */
            const uint32_t q_0__N_5_lo = q_0__N_5;
            c_6 += ul32_addc(&c_5, &c_5, &q_0__N_5_lo);
            const uint32_t q_0__N_4_hi = q_0__N_4 >> 32;
            c_6 += ul32_addc(&c_5, &c_5, &q_0__N_4_hi);
            const uint32_t q_1__N_4_lo = q_1__N_4;
            c_6 += ul32_addc(&c_5, &c_5, &q_1__N_4_lo);
            const uint32_t q_1__N_3_hi = q_1__N_3 >> 32;
            c_6 += ul32_addc(&c_5, &c_5, &q_1__N_3_hi);
            const uint32_t q_2__N_3_lo = q_2__N_3;
            c_6 += ul32_addc(&c_5, &c_5, &q_2__N_3_lo);
            const uint32_t q_2__N_2_hi = q_2__N_2 >> 32;
            c_6 += ul32_addc(&c_5, &c_5, &q_2__N_2_hi);
            const uint32_t q_3__N_2_lo = q_3__N_2;
            c_6 += ul32_addc(&c_5, &c_5, &q_3__N_2_lo);
            const uint32_t q_3__N_1_hi = q_3__N_1 >> 32;
            c_6 += ul32_addc(&c_5, &c_5, &q_3__N_1_hi);
            const uint32_t q_4__N_1_lo = q_4__N_1;
            c_6 += ul32_addc(&c_5, &c_5, &q_4__N_1_lo);
            const uint32_t q_4__N_0_hi = q_4__N_0 >> 32;
            c_6 += ul32_addc(&c_5, &c_5, &q_4__N_0_hi);
            
            /* Compute q_5 and add its product with N */
            q_5 = n->np * c_5;
            q_5__N_0 = ((uint64_t)q_5) * ((uint64_t)n->n->x[0]);
            q_5__N_1 = ((uint64_t)q_5) * ((uint64_t)n->n->x[1]);
            q_5__N_2 = ((uint64_t)q_5) * ((uint64_t)n->n->x[2]);
            q_5__N_3 = ((uint64_t)q_5) * ((uint64_t)n->n->x[3]);
            q_5__N_4 = ((uint64_t)q_5) * ((uint64_t)n->n->x[4]);
            q_5__N_5 = ((uint64_t)q_5) * ((uint64_t)n->n->x[5]);
            q_5__N_6 = ((uint64_t)q_5) * ((uint64_t)n->n->x[6]);
            q_5__N_7 = ((uint64_t)q_5) * ((uint64_t)n->n->x[7]);
            const uint32_t q_5__N_0_lo = q_5__N_0;
            c_6 += ul32_addc(&c_5, &c_5, &q_5__N_0_lo);
        }
        
        /* Compute c_6 */
        {
            /* Add the product terms into c_6, accumulating carries in c_7 */
            c_7 += ul32_addc(&c_6, &c_6, &a_0__b_5_hi);
            c_7 += ul32_addc(&c_6, &c_6, &a_0__b_6_lo);
            c_7 += ul32_addc(&c_6, &c_6, &a_1__b_4_hi);
            c_7 += ul32_addc(&c_6, &c_6, &a_1__b_5_lo);
            c_7 += ul32_addc(&c_6, &c_6, &a_2__b_3_hi);
            c_7 += ul32_addc(&c_6, &c_6, &a_2__b_4_lo);
            c_7 += ul32_addc(&c_6, &c_6, &a_3__b_2_hi);
            c_7 += ul32_addc(&c_6, &c_6, &a_3__b_3_lo);
            c_7 += ul32_addc(&c_6, &c_6, &a_4__b_1_hi);
            c_7 += ul32_addc(&c_6, &c_6, &a_4__b_2_lo);
            c_7 += ul32_addc(&c_6, &c_6, &a_5__b_0_hi);
            c_7 += ul32_addc(&c_6, &c_6, &a_5__b_1_lo);
            c_7 += ul32_addc(&c_6, &c_6, &a_6__b_0_lo);
            
            /* Add the q_i*N's for i < 6 */
            const uint32_t q_0__N_6_lo = q_0__N_6;
            c_7 += ul32_addc(&c_6, &c_6, &q_0__N_6_lo);
            const uint32_t q_0__N_5_hi = q_0__N_5 >> 32;
            c_7 += ul32_addc(&c_6, &c_6, &q_0__N_5_hi);
            const uint32_t q_1__N_5_lo = q_1__N_5;
            c_7 += ul32_addc(&c_6, &c_6, &q_1__N_5_lo);
            const uint32_t q_1__N_4_hi = q_1__N_4 >> 32;
            c_7 += ul32_addc(&c_6, &c_6, &q_1__N_4_hi);
            const uint32_t q_2__N_4_lo = q_2__N_4;
            c_7 += ul32_addc(&c_6, &c_6, &q_2__N_4_lo);
            const uint32_t q_2__N_3_hi = q_2__N_3 >> 32;
            c_7 += ul32_addc(&c_6, &c_6, &q_2__N_3_hi);
            const uint32_t q_3__N_3_lo = q_3__N_3;
            c_7 += ul32_addc(&c_6, &c_6, &q_3__N_3_lo);
            const uint32_t q_3__N_2_hi = q_3__N_2 >> 32;
            c_7 += ul32_addc(&c_6, &c_6, &q_3__N_2_hi);
            const uint32_t q_4__N_2_lo = q_4__N_2;
            c_7 += ul32_addc(&c_6, &c_6, &q_4__N_2_lo);
            const uint32_t q_4__N_1_hi = q_4__N_1 >> 32;
            c_7 += ul32_addc(&c_6, &c_6, &q_4__N_1_hi);
            const uint32_t q_5__N_1_lo = q_5__N_1;
            c_7 += ul32_addc(&c_6, &c_6, &q_5__N_1_lo);
            const uint32_t q_5__N_0_hi = q_5__N_0 >> 32;
            c_7 += ul32_addc(&c_6, &c_6, &q_5__N_0_hi);
            
            /* Compute q_6 and add its product with N */
            q_6 = n->np * c_6;
            q_6__N_0 = ((uint64_t)q_6) * ((uint64_t)n->n->x[0]);
            q_6__N_1 = ((uint64_t)q_6) * ((uint64_t)n->n->x[1]);
            q_6__N_2 = ((uint64_t)q_6) * ((uint64_t)n->n->x[2]);
            q_6__N_3 = ((uint64_t)q_6) * ((uint64_t)n->n->x[3]);
            q_6__N_4 = ((uint64_t)q_6) * ((uint64_t)n->n->x[4]);
            q_6__N_5 = ((uint64_t)q_6) * ((uint64_t)n->n->x[5]);
            q_6__N_6 = ((uint64_t)q_6) * ((uint64_t)n->n->x[6]);
            q_6__N_7 = ((uint64_t)q_6) * ((uint64_t)n->n->x[7]);
            const uint32_t q_6__N_0_lo = q_6__N_0;
            c_7 += ul32_addc(&c_6, &c_6, &q_6__N_0_lo);
        }
        
        /* Compute c_7 */
        {
            /* Add the product terms into c_7, accumulating carries in c_8 */
            c_8 += ul32_addc(&c_7, &c_7, &a_0__b_6_hi);
            c_8 += ul32_addc(&c_7, &c_7, &a_0__b_7_lo);
            c_8 += ul32_addc(&c_7, &c_7, &a_1__b_5_hi);
            c_8 += ul32_addc(&c_7, &c_7, &a_1__b_6_lo);
            c_8 += ul32_addc(&c_7, &c_7, &a_2__b_4_hi);
            c_8 += ul32_addc(&c_7, &c_7, &a_2__b_5_lo);
            c_8 += ul32_addc(&c_7, &c_7, &a_3__b_3_hi);
            c_8 += ul32_addc(&c_7, &c_7, &a_3__b_4_lo);
            c_8 += ul32_addc(&c_7, &c_7, &a_4__b_2_hi);
            c_8 += ul32_addc(&c_7, &c_7, &a_4__b_3_lo);
            c_8 += ul32_addc(&c_7, &c_7, &a_5__b_1_hi);
            c_8 += ul32_addc(&c_7, &c_7, &a_5__b_2_lo);
            c_8 += ul32_addc(&c_7, &c_7, &a_6__b_0_hi);
            c_8 += ul32_addc(&c_7, &c_7, &a_6__b_1_lo);
            c_8 += ul32_addc(&c_7, &c_7, &a_7__b_0_lo);
            
            /* Add the q_i*N's for i < 7 */
            const uint32_t q_0__N_7_lo = q_0__N_7;
            c_8 += ul32_addc(&c_7, &c_7, &q_0__N_7_lo);
            const uint32_t q_0__N_6_hi = q_0__N_6 >> 32;
            c_8 += ul32_addc(&c_7, &c_7, &q_0__N_6_hi);
            const uint32_t q_1__N_6_lo = q_1__N_6;
            c_8 += ul32_addc(&c_7, &c_7, &q_1__N_6_lo);
            const uint32_t q_1__N_5_hi = q_1__N_5 >> 32;
            c_8 += ul32_addc(&c_7, &c_7, &q_1__N_5_hi);
            const uint32_t q_2__N_5_lo = q_2__N_5;
            c_8 += ul32_addc(&c_7, &c_7, &q_2__N_5_lo);
            const uint32_t q_2__N_4_hi = q_2__N_4 >> 32;
            c_8 += ul32_addc(&c_7, &c_7, &q_2__N_4_hi);
            const uint32_t q_3__N_4_lo = q_3__N_4;
            c_8 += ul32_addc(&c_7, &c_7, &q_3__N_4_lo);
            const uint32_t q_3__N_3_hi = q_3__N_3 >> 32;
            c_8 += ul32_addc(&c_7, &c_7, &q_3__N_3_hi);
            const uint32_t q_4__N_3_lo = q_4__N_3;
            c_8 += ul32_addc(&c_7, &c_7, &q_4__N_3_lo);
            const uint32_t q_4__N_2_hi = q_4__N_2 >> 32;
            c_8 += ul32_addc(&c_7, &c_7, &q_4__N_2_hi);
            const uint32_t q_5__N_2_lo = q_5__N_2;
            c_8 += ul32_addc(&c_7, &c_7, &q_5__N_2_lo);
            const uint32_t q_5__N_1_hi = q_5__N_1 >> 32;
            c_8 += ul32_addc(&c_7, &c_7, &q_5__N_1_hi);
            const uint32_t q_6__N_1_lo = q_6__N_1;
            c_8 += ul32_addc(&c_7, &c_7, &q_6__N_1_lo);
            const uint32_t q_6__N_0_hi = q_6__N_0 >> 32;
            c_8 += ul32_addc(&c_7, &c_7, &q_6__N_0_hi);
            
            /* Compute q_7 and add its product with N */
            q_7 = n->np * c_7;
            q_7__N_0 = ((uint64_t)q_7) * ((uint64_t)n->n->x[0]);
            q_7__N_1 = ((uint64_t)q_7) * ((uint64_t)n->n->x[1]);
            q_7__N_2 = ((uint64_t)q_7) * ((uint64_t)n->n->x[2]);
            q_7__N_3 = ((uint64_t)q_7) * ((uint64_t)n->n->x[3]);
            q_7__N_4 = ((uint64_t)q_7) * ((uint64_t)n->n->x[4]);
            q_7__N_5 = ((uint64_t)q_7) * ((uint64_t)n->n->x[5]);
            q_7__N_6 = ((uint64_t)q_7) * ((uint64_t)n->n->x[6]);
            q_7__N_7 = ((uint64_t)q_7) * ((uint64_t)n->n->x[7]);
            const uint32_t q_7__N_0_lo = q_7__N_0;
            c_8 += ul32_addc(&c_7, &c_7, &q_7__N_0_lo);
        }
        
        /* Compute c_8 */
        {
            /* Add the product terms into c_8, accumulating carries in c_9 */
            c_9 += ul32_addc(&c_8, &c_8, &a_0__b_7_hi);
            c_9 += ul32_addc(&c_8, &c_8, &a_1__b_6_hi);
            c_9 += ul32_addc(&c_8, &c_8, &a_1__b_7_lo);
            c_9 += ul32_addc(&c_8, &c_8, &a_2__b_5_hi);
            c_9 += ul32_addc(&c_8, &c_8, &a_2__b_6_lo);
            c_9 += ul32_addc(&c_8, &c_8, &a_3__b_4_hi);
            c_9 += ul32_addc(&c_8, &c_8, &a_3__b_5_lo);
            c_9 += ul32_addc(&c_8, &c_8, &a_4__b_3_hi);
            c_9 += ul32_addc(&c_8, &c_8, &a_4__b_4_lo);
            c_9 += ul32_addc(&c_8, &c_8, &a_5__b_2_hi);
            c_9 += ul32_addc(&c_8, &c_8, &a_5__b_3_lo);
            c_9 += ul32_addc(&c_8, &c_8, &a_6__b_1_hi);
            c_9 += ul32_addc(&c_8, &c_8, &a_6__b_2_lo);
            c_9 += ul32_addc(&c_8, &c_8, &a_7__b_0_hi);
            c_9 += ul32_addc(&c_8, &c_8, &a_7__b_1_lo);
            
            /* Add the q_i*N's for i < 8 */
            const uint32_t q_0__N_7_hi = q_0__N_7 >> 32;
            c_9 += ul32_addc(&c_8, &c_8, &q_0__N_7_hi);
            const uint32_t q_1__N_7_lo = q_1__N_7;
            c_9 += ul32_addc(&c_8, &c_8, &q_1__N_7_lo);
            const uint32_t q_1__N_6_hi = q_1__N_6 >> 32;
            c_9 += ul32_addc(&c_8, &c_8, &q_1__N_6_hi);
            const uint32_t q_2__N_6_lo = q_2__N_6;
            c_9 += ul32_addc(&c_8, &c_8, &q_2__N_6_lo);
            const uint32_t q_2__N_5_hi = q_2__N_5 >> 32;
            c_9 += ul32_addc(&c_8, &c_8, &q_2__N_5_hi);
            const uint32_t q_3__N_5_lo = q_3__N_5;
            c_9 += ul32_addc(&c_8, &c_8, &q_3__N_5_lo);
            const uint32_t q_3__N_4_hi = q_3__N_4 >> 32;
            c_9 += ul32_addc(&c_8, &c_8, &q_3__N_4_hi);
            const uint32_t q_4__N_4_lo = q_4__N_4;
            c_9 += ul32_addc(&c_8, &c_8, &q_4__N_4_lo);
            const uint32_t q_4__N_3_hi = q_4__N_3 >> 32;
            c_9 += ul32_addc(&c_8, &c_8, &q_4__N_3_hi);
            const uint32_t q_5__N_3_lo = q_5__N_3;
            c_9 += ul32_addc(&c_8, &c_8, &q_5__N_3_lo);
            const uint32_t q_5__N_2_hi = q_5__N_2 >> 32;
            c_9 += ul32_addc(&c_8, &c_8, &q_5__N_2_hi);
            const uint32_t q_6__N_2_lo = q_6__N_2;
            c_9 += ul32_addc(&c_8, &c_8, &q_6__N_2_lo);
            const uint32_t q_6__N_1_hi = q_6__N_1 >> 32;
            c_9 += ul32_addc(&c_8, &c_8, &q_6__N_1_hi);
            const uint32_t q_7__N_1_lo = q_7__N_1;
            c_9 += ul32_addc(&c_8, &c_8, &q_7__N_1_lo);
            const uint32_t q_7__N_0_hi = q_7__N_0 >> 32;
            c_9 += ul32_addc(&c_8, &c_8, &q_7__N_0_hi);
            
        }
        
        /* Compute c_9 */
        {
            /* Add the product terms into c_9, accumulating carries in c_10 */
            c_10 += ul32_addc(&c_9, &c_9, &a_1__b_7_hi);
            c_10 += ul32_addc(&c_9, &c_9, &a_2__b_6_hi);
            c_10 += ul32_addc(&c_9, &c_9, &a_2__b_7_lo);
            c_10 += ul32_addc(&c_9, &c_9, &a_3__b_5_hi);
            c_10 += ul32_addc(&c_9, &c_9, &a_3__b_6_lo);
            c_10 += ul32_addc(&c_9, &c_9, &a_4__b_4_hi);
            c_10 += ul32_addc(&c_9, &c_9, &a_4__b_5_lo);
            c_10 += ul32_addc(&c_9, &c_9, &a_5__b_3_hi);
            c_10 += ul32_addc(&c_9, &c_9, &a_5__b_4_lo);
            c_10 += ul32_addc(&c_9, &c_9, &a_6__b_2_hi);
            c_10 += ul32_addc(&c_9, &c_9, &a_6__b_3_lo);
            c_10 += ul32_addc(&c_9, &c_9, &a_7__b_1_hi);
            c_10 += ul32_addc(&c_9, &c_9, &a_7__b_2_lo);
            
            /* Add the q_i*N's for i < 9 */
            const uint32_t q_1__N_7_hi = q_1__N_7 >> 32;
            c_10 += ul32_addc(&c_9, &c_9, &q_1__N_7_hi);
            const uint32_t q_2__N_7_lo = q_2__N_7;
            c_10 += ul32_addc(&c_9, &c_9, &q_2__N_7_lo);
            const uint32_t q_2__N_6_hi = q_2__N_6 >> 32;
            c_10 += ul32_addc(&c_9, &c_9, &q_2__N_6_hi);
            const uint32_t q_3__N_6_lo = q_3__N_6;
            c_10 += ul32_addc(&c_9, &c_9, &q_3__N_6_lo);
            const uint32_t q_3__N_5_hi = q_3__N_5 >> 32;
            c_10 += ul32_addc(&c_9, &c_9, &q_3__N_5_hi);
            const uint32_t q_4__N_5_lo = q_4__N_5;
            c_10 += ul32_addc(&c_9, &c_9, &q_4__N_5_lo);
            const uint32_t q_4__N_4_hi = q_4__N_4 >> 32;
            c_10 += ul32_addc(&c_9, &c_9, &q_4__N_4_hi);
            const uint32_t q_5__N_4_lo = q_5__N_4;
            c_10 += ul32_addc(&c_9, &c_9, &q_5__N_4_lo);
            const uint32_t q_5__N_3_hi = q_5__N_3 >> 32;
            c_10 += ul32_addc(&c_9, &c_9, &q_5__N_3_hi);
            const uint32_t q_6__N_3_lo = q_6__N_3;
            c_10 += ul32_addc(&c_9, &c_9, &q_6__N_3_lo);
            const uint32_t q_6__N_2_hi = q_6__N_2 >> 32;
            c_10 += ul32_addc(&c_9, &c_9, &q_6__N_2_hi);
            const uint32_t q_7__N_2_lo = q_7__N_2;
            c_10 += ul32_addc(&c_9, &c_9, &q_7__N_2_lo);
            const uint32_t q_7__N_1_hi = q_7__N_1 >> 32;
            c_10 += ul32_addc(&c_9, &c_9, &q_7__N_1_hi);
            
        }
        
        /* Compute c_10 */
        {
            /* Add the product terms into c_10, accumulating carries in c_11 */
            c_11 += ul32_addc(&c_10, &c_10, &a_2__b_7_hi);
            c_11 += ul32_addc(&c_10, &c_10, &a_3__b_6_hi);
            c_11 += ul32_addc(&c_10, &c_10, &a_3__b_7_lo);
            c_11 += ul32_addc(&c_10, &c_10, &a_4__b_5_hi);
            c_11 += ul32_addc(&c_10, &c_10, &a_4__b_6_lo);
            c_11 += ul32_addc(&c_10, &c_10, &a_5__b_4_hi);
            c_11 += ul32_addc(&c_10, &c_10, &a_5__b_5_lo);
            c_11 += ul32_addc(&c_10, &c_10, &a_6__b_3_hi);
            c_11 += ul32_addc(&c_10, &c_10, &a_6__b_4_lo);
            c_11 += ul32_addc(&c_10, &c_10, &a_7__b_2_hi);
            c_11 += ul32_addc(&c_10, &c_10, &a_7__b_3_lo);
            
            /* Add the q_i*N's for i < 10 */
            const uint32_t q_2__N_7_hi = q_2__N_7 >> 32;
            c_11 += ul32_addc(&c_10, &c_10, &q_2__N_7_hi);
            const uint32_t q_3__N_7_lo = q_3__N_7;
            c_11 += ul32_addc(&c_10, &c_10, &q_3__N_7_lo);
            const uint32_t q_3__N_6_hi = q_3__N_6 >> 32;
            c_11 += ul32_addc(&c_10, &c_10, &q_3__N_6_hi);
            const uint32_t q_4__N_6_lo = q_4__N_6;
            c_11 += ul32_addc(&c_10, &c_10, &q_4__N_6_lo);
            const uint32_t q_4__N_5_hi = q_4__N_5 >> 32;
            c_11 += ul32_addc(&c_10, &c_10, &q_4__N_5_hi);
            const uint32_t q_5__N_5_lo = q_5__N_5;
            c_11 += ul32_addc(&c_10, &c_10, &q_5__N_5_lo);
            const uint32_t q_5__N_4_hi = q_5__N_4 >> 32;
            c_11 += ul32_addc(&c_10, &c_10, &q_5__N_4_hi);
            const uint32_t q_6__N_4_lo = q_6__N_4;
            c_11 += ul32_addc(&c_10, &c_10, &q_6__N_4_lo);
            const uint32_t q_6__N_3_hi = q_6__N_3 >> 32;
            c_11 += ul32_addc(&c_10, &c_10, &q_6__N_3_hi);
            const uint32_t q_7__N_3_lo = q_7__N_3;
            c_11 += ul32_addc(&c_10, &c_10, &q_7__N_3_lo);
            const uint32_t q_7__N_2_hi = q_7__N_2 >> 32;
            c_11 += ul32_addc(&c_10, &c_10, &q_7__N_2_hi);
            
        }
        
        /* Compute c_11 */
        {
            /* Add the product terms into c_11, accumulating carries in c_12 */
            c_12 += ul32_addc(&c_11, &c_11, &a_3__b_7_hi);
            c_12 += ul32_addc(&c_11, &c_11, &a_4__b_6_hi);
            c_12 += ul32_addc(&c_11, &c_11, &a_4__b_7_lo);
            c_12 += ul32_addc(&c_11, &c_11, &a_5__b_5_hi);
            c_12 += ul32_addc(&c_11, &c_11, &a_5__b_6_lo);
            c_12 += ul32_addc(&c_11, &c_11, &a_6__b_4_hi);
            c_12 += ul32_addc(&c_11, &c_11, &a_6__b_5_lo);
            c_12 += ul32_addc(&c_11, &c_11, &a_7__b_3_hi);
            c_12 += ul32_addc(&c_11, &c_11, &a_7__b_4_lo);
            
            /* Add the q_i*N's for i < 11 */
            const uint32_t q_3__N_7_hi = q_3__N_7 >> 32;
            c_12 += ul32_addc(&c_11, &c_11, &q_3__N_7_hi);
            const uint32_t q_4__N_7_lo = q_4__N_7;
            c_12 += ul32_addc(&c_11, &c_11, &q_4__N_7_lo);
            const uint32_t q_4__N_6_hi = q_4__N_6 >> 32;
            c_12 += ul32_addc(&c_11, &c_11, &q_4__N_6_hi);
            const uint32_t q_5__N_6_lo = q_5__N_6;
            c_12 += ul32_addc(&c_11, &c_11, &q_5__N_6_lo);
            const uint32_t q_5__N_5_hi = q_5__N_5 >> 32;
            c_12 += ul32_addc(&c_11, &c_11, &q_5__N_5_hi);
            const uint32_t q_6__N_5_lo = q_6__N_5;
            c_12 += ul32_addc(&c_11, &c_11, &q_6__N_5_lo);
            const uint32_t q_6__N_4_hi = q_6__N_4 >> 32;
            c_12 += ul32_addc(&c_11, &c_11, &q_6__N_4_hi);
            const uint32_t q_7__N_4_lo = q_7__N_4;
            c_12 += ul32_addc(&c_11, &c_11, &q_7__N_4_lo);
            const uint32_t q_7__N_3_hi = q_7__N_3 >> 32;
            c_12 += ul32_addc(&c_11, &c_11, &q_7__N_3_hi);
            
        }
        
        /* Compute c_12 */
        {
            /* Add the product terms into c_12, accumulating carries in c_13 */
            c_13 += ul32_addc(&c_12, &c_12, &a_4__b_7_hi);
            c_13 += ul32_addc(&c_12, &c_12, &a_5__b_6_hi);
            c_13 += ul32_addc(&c_12, &c_12, &a_5__b_7_lo);
            c_13 += ul32_addc(&c_12, &c_12, &a_6__b_5_hi);
            c_13 += ul32_addc(&c_12, &c_12, &a_6__b_6_lo);
            c_13 += ul32_addc(&c_12, &c_12, &a_7__b_4_hi);
            c_13 += ul32_addc(&c_12, &c_12, &a_7__b_5_lo);
            
            /* Add the q_i*N's for i < 12 */
            const uint32_t q_4__N_7_hi = q_4__N_7 >> 32;
            c_13 += ul32_addc(&c_12, &c_12, &q_4__N_7_hi);
            const uint32_t q_5__N_7_lo = q_5__N_7;
            c_13 += ul32_addc(&c_12, &c_12, &q_5__N_7_lo);
            const uint32_t q_5__N_6_hi = q_5__N_6 >> 32;
            c_13 += ul32_addc(&c_12, &c_12, &q_5__N_6_hi);
            const uint32_t q_6__N_6_lo = q_6__N_6;
            c_13 += ul32_addc(&c_12, &c_12, &q_6__N_6_lo);
            const uint32_t q_6__N_5_hi = q_6__N_5 >> 32;
            c_13 += ul32_addc(&c_12, &c_12, &q_6__N_5_hi);
            const uint32_t q_7__N_5_lo = q_7__N_5;
            c_13 += ul32_addc(&c_12, &c_12, &q_7__N_5_lo);
            const uint32_t q_7__N_4_hi = q_7__N_4 >> 32;
            c_13 += ul32_addc(&c_12, &c_12, &q_7__N_4_hi);
            
        }
        
        /* Compute c_13 */
        {
            /* Add the product terms into c_13, accumulating carries in c_14 */
            c_14 += ul32_addc(&c_13, &c_13, &a_5__b_7_hi);
            c_14 += ul32_addc(&c_13, &c_13, &a_6__b_6_hi);
            c_14 += ul32_addc(&c_13, &c_13, &a_6__b_7_lo);
            c_14 += ul32_addc(&c_13, &c_13, &a_7__b_5_hi);
            c_14 += ul32_addc(&c_13, &c_13, &a_7__b_6_lo);
            
            /* Add the q_i*N's for i < 13 */
            const uint32_t q_5__N_7_hi = q_5__N_7 >> 32;
            c_14 += ul32_addc(&c_13, &c_13, &q_5__N_7_hi);
            const uint32_t q_6__N_7_lo = q_6__N_7;
            c_14 += ul32_addc(&c_13, &c_13, &q_6__N_7_lo);
            const uint32_t q_6__N_6_hi = q_6__N_6 >> 32;
            c_14 += ul32_addc(&c_13, &c_13, &q_6__N_6_hi);
            const uint32_t q_7__N_6_lo = q_7__N_6;
            c_14 += ul32_addc(&c_13, &c_13, &q_7__N_6_lo);
            const uint32_t q_7__N_5_hi = q_7__N_5 >> 32;
            c_14 += ul32_addc(&c_13, &c_13, &q_7__N_5_hi);
            
        }
        
        /* Compute c_14 */
        {
            /* Add the product terms into c_14, accumulating carries in c_15 */
            c_15 += ul32_addc(&c_14, &c_14, &a_6__b_7_hi);
            c_15 += ul32_addc(&c_14, &c_14, &a_7__b_6_hi);
            c_15 += ul32_addc(&c_14, &c_14, &a_7__b_7_lo);
            
            /* Add the q_i*N's for i < 14 */
            const uint32_t q_6__N_7_hi = q_6__N_7 >> 32;
            c_15 += ul32_addc(&c_14, &c_14, &q_6__N_7_hi);
            const uint32_t q_7__N_7_lo = q_7__N_7;
            c_15 += ul32_addc(&c_14, &c_14, &q_7__N_7_lo);
            const uint32_t q_7__N_6_hi = q_7__N_6 >> 32;
            c_15 += ul32_addc(&c_14, &c_14, &q_7__N_6_hi);
            
        }
        
        /* Compute c_15 */
        {
            /* Add the product terms into c_15, accumulating carries in c_16 */
            c_16 += ul32_addc(&c_15, &c_15, &a_7__b_7_hi);
            
            /* Add the q_i*N's for i < 15 */
            const uint32_t q_7__N_7_hi = q_7__N_7 >> 32;
            c_16 += ul32_addc(&c_15, &c_15, &q_7__N_7_hi);
            
        }
        
        /* R = C * beta^{-n} */
        _dst->x[0] = c_8;
        _dst->x[1] = c_9;
        _dst->x[2] = c_10;
        _dst->x[3] = c_11;
        _dst->x[4] = c_12;
        _dst->x[5] = c_13;
        _dst->x[6] = c_14;
        _dst->x[7] = c_15;
        
        /* Reduce as needed */
        if (c_16 || (ul256_cmp(_dst, n->n) >= 0))
            ul256_sub(_dst, _dst, n->n);
    #endif
}

/*
 * Convert a ul256 into Montgomery form
 */
inline void ul256_to_montgomery(ul256 dst, ul256 src, mod256 mod) {
    ul256_modmul(dst, src, mod->rsq, mod);
}

/*
 * Convert a ul256 out-of Montgomery form
 */
inline void ul256_from_montgomery(ul256 dst, ul256 src, mod256 mod) {
    ul256 one = {{{0}}};
    one->x[0] = 1;
    
    ul256_modmul(dst, src, one, mod);
}




/*
 * Right-shift a ul256 by some number of bits
 */
inline void ul256_rshift(ul256 dst, ul256 src, int shift) {
dst->x[0] = (src->x[0] >> shift) | (src->x[1] << (32 - shift));
dst->x[1] = (src->x[1] >> shift) | (src->x[2] << (32 - shift));
dst->x[2] = (src->x[2] >> shift) | (src->x[3] << (32 - shift));
dst->x[3] = (src->x[3] >> shift) | (src->x[4] << (32 - shift));
dst->x[4] = (src->x[4] >> shift) | (src->x[5] << (32 - shift));
dst->x[5] = (src->x[5] >> shift) | (src->x[6] << (32 - shift));
dst->x[6] = (src->x[6] >> shift) | (src->x[7] << (32 - shift));
dst->x[7] = dst->x[7] >> shift;
}



/*
 * Left shift a ul256 by some number of words
 */
inline void ul256_lshiftw(ul256 dst, ul256 src, int w) {
    dst->x[7] = ((7-w) >= 0) ? src->x[7-w] : 0;
    dst->x[6] = ((6-w) >= 0) ? src->x[6-w] : 0;
    dst->x[5] = ((5-w) >= 0) ? src->x[5-w] : 0;
    dst->x[4] = ((4-w) >= 0) ? src->x[4-w] : 0;
    dst->x[3] = ((3-w) >= 0) ? src->x[3-w] : 0;
    dst->x[2] = ((2-w) >= 0) ? src->x[2-w] : 0;
    dst->x[1] = ((1-w) >= 0) ? src->x[1-w] : 0;
    dst->x[0] = ((0-w) >= 0) ? src->x[0-w] : 0;
}

/*
 * Multiply a ul256 by a uint32_t
 */
inline void ul256_mulu32(ul256 dst, ul256 src, uint32_t x) {
    uint64_t x_src_0 = ((uint64_t)src->x[0]) * ((uint64_t)x);
    uint64_t x_src_1 = ((uint64_t)src->x[1]) * ((uint64_t)x);
    uint64_t x_src_2 = ((uint64_t)src->x[2]) * ((uint64_t)x);
    uint64_t x_src_3 = ((uint64_t)src->x[3]) * ((uint64_t)x);
    uint64_t x_src_4 = ((uint64_t)src->x[4]) * ((uint64_t)x);
    uint64_t x_src_5 = ((uint64_t)src->x[5]) * ((uint64_t)x);
    uint64_t x_src_6 = ((uint64_t)src->x[6]) * ((uint64_t)x);
    uint64_t x_src_7 = ((uint64_t)src->x[7]) * ((uint64_t)x);
    
    dst->x[0] = 0;
    dst->x[1] = 0;
    dst->x[2] = 0;
    dst->x[3] = 0;
    dst->x[4] = 0;
    dst->x[5] = 0;
    dst->x[6] = 0;
    dst->x[7] = 0;
    
    *(uint64_t*)(&dst->x[0]) += x_src_0;
    *(uint64_t*)(&dst->x[1]) += x_src_1;
    *(uint64_t*)(&dst->x[2]) += x_src_2;
    *(uint64_t*)(&dst->x[3]) += x_src_3;
    *(uint64_t*)(&dst->x[4]) += x_src_4;
    *(uint64_t*)(&dst->x[5]) += x_src_5;
    *(uint64_t*)(&dst->x[6]) += x_src_6;
    dst->x[7] += x_src_7 >> 32;
}




#endif
